\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encodings may result in incorrect characters.
%
\usepackage{graphicx}

\usepackage{soul}
\usepackage{multicol}
\usepackage[dvipsnames]{xcolor}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{array}
\usepackage{multirow}
\usepackage[noend]{algorithm2e}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{hyperref}

\begin{document}
\SetNlSty{bfseries}{\color{black}}{}

\lstset{breaklines=true}

\newcommand\ty[1]{\textsf{#1}}
\newcommand\sym[1]{\textsf{#1}}
\newcommand\var[1]{\mathit{#1}}

%% TYPESETTING: hacks
\newcommand\medrightarrow{\mathrel{{{\color{black}\relbar}\kern-0.9ex\rlap{\color{white}\ensuremath{\blacksquare}}\kern-0.9ex}\joinrel{\color{black}\rightarrow}}}
\newcommand\medleftarrow{\mathrel{{\color{black}\leftarrow}\kern-0.9ex\rlap{\color{white}\ensuremath{\blacksquare}}\kern-0.9ex\joinrel{{\color{black}\relbar}}}}
\newcommand\medleftrightarrow{\mathrel{\leftarrow\kern-1.685ex\rightarrow}}
\newcommand\Medrightarrow{\mathrel{{{\color{black}\Relbar}\kern-0.9ex\rlap{\color{white}\ensuremath{\blacksquare}}\kern-0.9ex}\joinrel{\color{black}\Rightarrow}}}
\newcommand\Medleftrightarrow{\mathrel{\Leftarrow\kern-1.685ex\Rightarrow}}

\def\negvthinspace{\kern-0.083333em}
\def\vthinspace{\kern+0.083333em}

\hyphenation{mono-mor-phisa-tion}
\hyphenation{mono-mor-phic}
\hyphenation{non-mono-mor-phic}

%\newtheorem{definition}{Definition}
\newtheorem{examplex}[definition]{Example}

\setlist[itemize]{topsep=5pt, itemsep=0pt}
\setlist[enumerate]{topsep=5pt, itemsep=0pt}

% algo2e package
\SetFuncSty{textit}
\SetFuncArgSty{text}
\SetArgSty{text}
\SetDataSty{text}

\DontPrintSemicolon

% some keywords
\SetKwFunction{GenFormulae}{generate\_mono\_formulae}
\SetKw{ST}{such that}

% bounds keywords
\SetKwData{MonoCap}{\textcolor{ourblueviolet}{mono\_cap}}
\SetKwData{MonoMult}{\textcolor{ourblueviolet}{mono\_mult}}
\SetKwData{MonoFloor}{\textcolor{ourblueviolet}{mono\_floor}}
\SetKwData{PolyCap}{\textcolor{ourblueviolet}{nonm\_cap}}
\SetKwData{PolyMult}{\textcolor{ourblueviolet}{nonm\_mult}}
\SetKwData{PolyFloor}{\textcolor{ourblueviolet}{nonm\_floor}}
\SetKwData{MaxMono}{\textcolor{ourblueviolet}{max\_mono\_args}}
\SetKwData{MaxPoly}{\textcolor{ourblueviolet}{max\_nonm\_args}}
\SetKwData{Limit}{\textcolor{ourblueviolet}{max\_new\_formulae}}
\SetKwData{MonoSubstsLimit}{\textcolor{ourblueviolet}{max\_substs}}
\SetKwData{SubstLimit}{\textcolor{ourblueviolet}{substitution\_cap}}
\SetKwData{Loop}{\textcolor{ourblueviolet}{num\_loops}}
\SetKwData{TypeVars}{type\_vars}
\SetKwData{UsedSubst}{\(S\)}

\SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{Stop}{stop}

\SetKwFunction{Max}{max}\SetKwFunction{Min}{min}
\SetKwFunction{Domain}{subst\_dom}\SetKwFunction{Len}{len}
\SetKwFunction{SubstGen}{matches}\SetKwFunction{TyVars}{type\_vars}
\SetKwFunction{FMonoStep}{formula\_mono\_step}
\SetKwProg{Fn}{Function}{}{end}\SetKwFunction{FRecurs}{FnRecursive}%
\newcommand{\forcond}{$i=0$ \KwTo $n$}

\definecolor{ourblueviolet}{rgb}{0.1, 0.5, 0.9}
\definecolor{grey}{rgb}{0.8,0.8,0.8}
\definecolor{algoColorKeyword}{named}{grey}
\makeatletter
% Block with a vertical line
\renewcommand{\algocf@Vsline}[1]{%
   \strut\par\nointerlineskip%
   \algocf@bblockcode%
   \algocf@push{\skiprule}%
   \hbox{{\color{algoColorKeyword}\vrule}%
      \vtop{\algocf@push{\skiptext}%
      \vtop{\algocf@addskiptotal\advance\hsize by -\skiplength #1}}%
   }%
   \algocf@pop{\skiprule}%
   \algocf@bblockcode%
}
\makeatother


%\copyrightyear{2024}
%\copyrightclause{Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)}
%
%\conference{Submitted draft} % TODO update

% TODO, at the end check the following
%   - formulas -> formulae
%   - clause -> formula
%   - terms in ``xxx'' -> \emph{xxx}
%   - monomorphization -> monomorphisation
%   - higher-order -> higher order
%   - TH1 with ugly 1
%   - correctly spelled TPTP, Leo-III, Zipperposition, E, Vampire
%   - polymorphic and monomorphic
%   - title of bits of the algorithms
%   - TH1 ugly for height of 1 reasons, can be fixed with case feature
%   - eg or ex -> e.g.
%   - function symbol -> symbol instance (depends on context)
%   - ... -> \dots
%   - comma splices!!!!
%   - add \; at the end of each algorithm line
%   - ``'' -> `'
%   - use \Phi instead of F for formulae
%   - concrete types -> monomorphic types
%   - use in not \in when we are not precisely dealing with set membership
%   - $\Phi$ for problem and $\varphi_1$ etc.
%   - n-uples -> n-tuples
%   - ize -> ise (in cas i forgot any)
%   - remove vertical space before lists (if allowed)
%   - add full stops to end of sentences in itemize
%   - B\"ome -> B\"ohme

\title{Iterative Monomorphisation}

\def\orcid#1{{\href{http://orcid.org/#1}{\protect\raisebox{-1.25pt}{\protect\includegraphics{orcid.pdf}}}}}

\author{Tanguy Bozec\inst{1,2}\orcid{0009-0005-9497-4168} \and
Jasmin Blanchette\inst{2}\orcid{0000-0002-8367-0936}}

\authorrunning{T. Bozec and J. Blanchette}

\institute{ENS Paris-Saclay, Université Paris-Saclay, France \and
%Institute of Informatics,
Ludwig-Maximilians-Universität München, Germany}


\maketitle

\begin{sloppy}
\begin{abstract}
Monomorphisation can be used to extend monomorphic provers to support polymorphic logics. We describe a pragmatic iterative approach. We implemented it in the Zipperposition prover, where it is used to translate away polymorphism before invoking the monomorphic prover E as a backend. Our evaluation shows that this approach increases Zipperposition's success rate. Moreover, we find that iterative monomorphisation outperforms some native implementations of polymorphism.

\keywords{Polymorphism  \and monomorphism \and automated reasoning}
\end{abstract}
\end{sloppy}

% target page number: 2-2.5
\section{Introduction}

Automatic theorem provers provide automation for proof assistant users. Many proof assistants, such as HOL4~\cite{slind-norrish-2008}, HOL Light~\cite{harrison-2009} and Isabelle\slash HOL \cite{nipkow-et-al-2002}, support rank~1 polymorphism, where type quantification is allowed at the top level of formulae. By contrast, many automatic provers only work with monomorphic logics. One way to close this gap is to extend provers to natively support polymorphism, as has been done in Vampire~\cite{bhayat-reger-2020}. However, this entails a lot of work that must be redone for every prover.
%
The alternative is to translate polymorphic problems to monomorphic problems.

One approach \cite{mono-trans} is to encode a complete polymorphic type system, %using dedicated function or predicate symbols in a monomorphic logic,
but this increases the size of the input problem substantially and slows down provers \cite{mono-trans}.
%
Another approach to encode polymorphism is based on {iterative monomorphisation}, as described by B\"ohme~\cite[Section 2.2.1]{sb-phd}.
%
Iterative monomorphisation heuristically instantiates the formulae's type variables with concrete types.
%
However, any translation relying on a finite number of instantiations is inevitably incomplete.
By a typed version of the compactness theorem, for any first order polymorphic formula \(\varphi\), there exists an equisatisfiable finite set of monomorphic instances of~\(\varphi\), but
it cannot be computed in general~\cite[Theorem~1]{expr-poly-types}.

B\"ohme's approach is implemented as part of Isabelle/HOL's SMT (satisfiability modulo theories) integration~\cite[Chapter 2]{sb-phd}. This implementation is also used by Sledgehammer~\cite{judgement,paulson-blanchette-2010} to interface with superposition based automatic theorem provers. However, it is documented only as a single subsection in B\"ohme's PhD thesis~\cite[Section 2.2.1]{sb-phd}.
\relax{SMT-LIB} also uses iterative monomorphisation \cite{smt-lib-mono}.
Moreover, a similar algorithm appears to be implemented in the \relax{MESON} tactic~\cite{harrison-1996} of HOL Light, but it is undocumented.

In this paper, we present an algorithm based on our understanding of Böhme's description and implementation (Section~\ref{sec:high level-algorithm}). We also provide a more detailed\pagebreak[2] \hbox{description} to help future implementers. In addition, we present some optimisations
to curb the combinatorial explosions (Section~\ref{sec:low-level-algorithm}).
% some of the ways in which an implementation can be made more efficient and avoid combinatorial explosions (Section~\ref{sec:low-level-algorithm}).

The algorithm works as follows. The input problem is a set of formulae. All the problem's symbols are collected, and the polymorphic symbol instances are matched against the monomorphic ones. This yields new symbol instances, both polymorphic and monomorphic. The process is then iterated, making use of the newly generated instances.
%
Consider the unary type constructor \ty{list}. If a formula contains $\ty{list}(\alpha)$, where $\alpha$ is a type variable, the types $\ty{list}(\ty{int})$, $\ty{list}(\ty{list}(\ty{int}))$, etc., can be generated. However, because new types emerge through matching, $\ty{list}(\ty{list}(\ty{int}))$ can be obtained only once the $\ty{list}(\ty{int})$ instance has been generated.
%This example also shows that an infinite set of instances could be produced if the algorithm kept going for ever.

To keep the number of generated formulae finite, we limit the number of iterations. After the iterations are completed, the new monomorphic symbol instances are used to instantiate the polymorphic symbols in the problem's formulae, generating new monomorphic formulae. Finally, because monomorphic provers support only nullary type constructors, types must be `mangled'; for example, the compound type $\ty{list}(\ty{int})$ might be mangled to $\ty{list\_int}$.

We implemented iterative monomorphisation in Zipperposition~\cite{vukmirovic-et-al-2021}, a higher order prover written in OCaml. Although Zipperposition is polymorphic, it uses the monomorphic prover E~\cite{e} as a backend. Thanks to our work, E can now be used with polymorphic problems. Moreover, our implementation can be used as a preprocessor for other stand-alone provers.
Our source code is available online.%
\footnote{\url{https://github.com/nartannt/iterative_monomorphisation}}
%
Our evaluation on the TPTP~\cite{tptp} tries to answer three questions (Section~\ref{sec:evaluation}):
\begin{enumerate}
\item Is the new Zipperposition with the E backend more successful on polymorphic problems than Zipperposition without backend?

\item How competitive are monomorphic provers on monomorphised %polymorphic
problems?

\item Is iterative monomorphisation more effective than the native polymorphism implemented in polymorphic provers?
\end{enumerate}

%Our findings are as follows:
%\begin{enumerate}
%\item Zipperposition benefits substantially from the E backend.
%
%\item E with monomorphisation comes close second to the polymorphic prover Vampire.
%
%\item For Leo-III~\cite{leo-iii} and Vampire~\cite{vamp}, we find that monomorphisation is indeed more effective than native polymorphism.
%\end{enumerate}

\kern-1pt %%% TYPESETTING: Hack

% target page number: 0.5-1.5
\section{Preliminaries}
\label{sec:preliminaries}

Our algorithm works independently of the structure of the problem's formulae. It relies exclusively on the formulae's monomorphic and polymorphic symbol instances. Type variables are assumed to be implicitly universally quantified at a formula's top level. The precise form of formulae is left unspecified.
Due to this generality, iterative monomorphisation can be used with any standard variant of rank~1 polymorphic logic. In particular, it can work with the polymorphic first and higher order logics embodied by TPTP's TF1 and TH1 syntaxes~\cite{blanchette-paskevich-2013,th1}.
% implemented by several automatic provers.

Our abstract framework relies on the following basic definitions.

\begin{definition}\rm
A (\emph{polymorphic}) \emph{type} \(\tau\) is a type variable (e.g.\ \(\alpha\)) or
the application of an \(n\)-ary type constructor to \(n\) types (e.g.\ \(\ty{list}(\alpha)\), \(\ty{map}(\ty{int},\ty{string})\)).
If
$n = 0$, we omit the parentheses (e.g.\ \(\ty{int}\)).
A type is \emph{monomorphic} if it contains no type variables.
\end{definition}

\begin{definition}\rm
A (function or predicate) {symbol} \(f\) has a \emph{type arity} that specifies the number of type arguments it takes. A \emph{symbol instance} is a symbol applied to type arguments listed between angle brackets: \(f\langle \tau_1, \dots, \tau_n\rangle\), where each $\tau_i$ is a type. If $n = 0$, we omit the angle brackets (e.g.\ $f$).
\end{definition}

\begin{definition}\rm
A (\emph{type}) \emph{substitution} is a partial function mapping a finite number of type variables to corresponding types. Substitutions are written as
$\sigma = \{\alpha_1\mapsto\tau_1, \dots, \alpha_n\mapsto\tau_n\}$. They are assumed to be lifted to formulae; thus, $\sigma(\varphi)$ yields the variant of $\varphi$ in which each $\alpha_i$ is replaced by $\tau_i$.
Given two substitutions \(\tau, \upsilon\), the successive application of \(\tau\) and \(\upsilon\) is denoted by \(\upsilon \circ \tau\).
\end{definition}

\begin{definition}\rm
Two substitutions \(\{\alpha_1 \mapsto \tau_1, \dots, \alpha_m\mapsto\tau_m\}\) and \(\{\beta_1 \mapsto \upsilon_1, \dots,\allowbreak \beta_n\mapsto\upsilon_n\}\) are said to be \emph{compatible} if \(\alpha_i = \beta_j\) implies \(\tau_i = \upsilon_j\) for all \(i, j\).
\end{definition}

\begin{definition}\rm
Given two types \(\tau, \upsilon\), \emph{matching} \(\upsilon\) against \(\tau\) either fails or yields a substitution \(\sigma\) such that \(\sigma(\upsilon) = \tau\).
\end{definition}

%In the following sections, we will always match a polymorphic type $\upsilon$ against a monomorphic type $\tau$.

% target page number: 2-4
\section{High level algorithm}
\label{sec:high level-algorithm}

The iterative monomorphisation algorithm takes a polymorphic problem as input and returns a monomorphic problem. It works by applying a bounded number of iterations, each taking a polymorphic problem as argument and returning a problem with new partially instantiated formulae. A single iteration consists of a collection phase and an instantiation phase. Once the iterations are completed, a final step discards all non-monomorphic formulae returned by the last iteration.

The initial phase of each iteration computes two maps, \(M\) and \(N\), from the input problem~$\Phi$.
%
\begin{enumerate}
\item[\labelitemi] Given a symbol \(f\) occurring in \(\Phi\), the set \(M(f)\) consists of all monomorphic type argument tuples to which \(f\) is applied in \(\Phi\). For example, if \(\sym{foldl}\langle \ty{nat}, \ty{int}\rangle\) occurs in \(\Phi\), then \((\ty{nat}, \ty{int}) \in M(\sym{foldl}) \).

\item[\labelitemi] Given a formula \(\varphi \in \Phi\) and a symbol \(f\) occurring in \(\varphi\), the set \(N(\varphi)(f)\) consists of all type argument tuples to which \(f\) is applied in \(\varphi\) and which contain a type variable. For example, if \(\sym{foldl}\langle \ty{nat}, \ty{list}(\alpha)\rangle\) occurs in \(\varphi\), then \((\ty{nat}, \ty{list}(\alpha)) \in N(\varphi)(\sym{foldl}) \).
\end{enumerate}

%These definitions depend on the precise form of the input formulae, which has been left undefined.
\(N\) is parametrised with \(\varphi\) because type variables are implicitly quantified at the formula level. The formula indicates the scope of type variables. This is not necessary for \(M\) since all the types it contains are monomorphic.

Once the maps \(M\) and \(N\) are initialised, each iteration performs the following steps to create new instances of formulae:

\begin{enumerate}

   \item Create an empty set of formulae \(\Phi'\).

\pagebreak[2]

   \item For each formula \(\varphi \in \Phi\) and for each symbol \(f\) occurring in \(\varphi\):
   \begin{enumerate}
    \item[2.1.] For each \((\tau_1, \dots, \tau_n) \in  M(f)\) and \((\upsilon_1, \dots, \upsilon_n) \in N(\varphi)(f)\) and
     for each \(i\), match \(\upsilon_i\) against \(\tau_i\), yielding the substitution \(\sigma_i\) in case of success.

    \item[2.2.] If all \(n\) matchings are successful and the substitutions \(\sigma_i\) are pairwise compatible,
add the formula \((\sigma_1 \circ \dots \circ \sigma_n)(\varphi)\) to \(\Phi'\).
   \end{enumerate}

   \item Return \(\Phi \cup \Phi'\).

\end{enumerate}

The algorithm is trivially sound because the newly generated formulae are instances of the initial problem's formulae. %, where type variables have been instantiated with monomorphic types.
However, it is not complete.

\begin{examplex}\rm
Consider the following problem:
\begin{enumerate}
   \item[$\langle1\rangle$] \(\sym{p}\langle \ty{int}\rangle(0)\)
   \item[$\langle2\rangle$] \(\forall a: \alpha{,}\; \mathit{as}:\ty{list}(\alpha){.}\; \sym{p}\langle\alpha\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\alpha)\rangle(\mathit{as})\)
\end{enumerate}
%
The first iteration matches \(\alpha\) against \(\ty{int}\) for $\sym{p}$, generating the formula
%
\begin{enumerate}
   \item[$\langle3\rangle$] \(\forall a: \ty{int}{,}\; \mathit{as}:\ty{list}(\ty{int}){.}\; \sym{p}\langle\ty{int}\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\ty{int})\rangle(\mathit{as})\)
\end{enumerate}
%
The second iteration matches \(\alpha\) against \(\ty{list}(\ty{int})\), leading to the formula
%
\begin{enumerate}
   \item[$\langle4\rangle$] \(\forall a: \ty{list}(\ty{int}){,}\; \mathit{as}:\ty{list}(\ty{list}(\ty{int})){.}\; \sym{p}\langle\ty{list}(\ty{int})\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\ty{list}(\ty{int}))\rangle(\mathit{as})\)
\end{enumerate}
%
Similarly the third iteration adds
%
\begin{enumerate}
   \item[$\langle5\rangle$]
         \( \forall a: \ty{list}(\ty{list}(\ty{int})){,}\; \mathit{as}:\ty{list}(\ty{list}(\ty{list}(\ty{int}))){.} \\ \sym{p}\langle\ty{list}(\ty{list}(\ty{int}))\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\ty{list}(\ty{list}(\ty{int})))\rangle(\mathit{as})\)
\end{enumerate}

\end{examplex}

This example illustrates how an infinite number of new formulae can be generated from a simple initial problem.
%Although the example may seem contrived, similar problems frequently arise in practice. For example, the \sym{concat} function of Isabelle/HOL, which is characterised in the base case by the equation \(\sym{concat}\langle\alpha\rangle\; \sym{Nil}\langle\ty{list}(\alpha)\rangle = \sym{Nil}\langle\alpha\rangle\), exhibits the same behavior.
Any reasonable implementation must limit the number of new type arguments, substitutions and formulae.


% target page number: 2-4
\section{Low level algorithm}
\label{sec:low-level-algorithm}

\looseness=-1
The algorithm presented above is too naïve in practice. In this section, we present a lower level algorithm with the following features.
First, numeric bounds are introduced to stop combinatorially explosive enumerations.
Second, type argument tuples are separated into an old set and a new set to avoid re-computing some of the same matchings in successive iterations.
Third, substitutions are directly applied to the type arguments instead of the formulae. This avoids having to re-extract the type arguments from the formulae at each iteration. New formulae are generated only once all iterations are completed, in a separate, final step.

The data structures used in the algorithm are based on the ones used in the high level description. Instead of a map \(M\) from symbols to monomorphic type argument tuples, we now have \(M_\text{old}\) and \(M_\text{new}\), which play the same role whilst also distinguishing between those type argument tuples that have already been matched against and those that have not. Similarly, \(N_\text{old}\) and \(N_\text{new}\) replace the map \(N\) from formulae to symbols to non-monomorphic type argument tuples. Finally, we maintain a map \(S\) from formulae to the substitutions generated by the matchings. It is used to generate new formulae in the final phase.

All sets referenced in the algorithm are %assumed to be
finite. Moreover, the algorithm relies on primitives whose implementation depends on the specifics of the grammar and logic used. %They will therefore not be expanded upon.
Functions computing the following are assumed to be available: 
\begin{enumerate}
   \item[\labelitemi] \emph{initialisation\((\Phi)\)}, where \(\Phi\) is a set of (polymorphic) formulae, extracts the initial type argument maps \(M\) and \(N\) from \(\Phi\).
   \item[\labelitemi] \emph{type\_vars\((\tau_1, \dots, \tau_n)\)}, where \(\tau_1, \dots,\tau_n\) are types, gathers all the type variables from each type \(\tau_1, \dots, \tau_n\) into a set. This function is overloaded to accept a formula \(\varphi\) as input, in which case it returns the set of all type variables which occur in the formula.
   \item[\labelitemi] \emph{match\((\upsilon, \tau)\)}, where \(\upsilon\) and \(\tau\) are types, matches \(\upsilon\) against \(\tau\) and either fails or returns \emph{Some\((\sigma)\)}, where \(\sigma\) results from the matching. The algorithm matches only non-monomorphic types against monomorphic types.
   \item[\labelitemi] \emph{domain\((\sigma)\)} %, where \(\sigma\) is a substitution,
   returns the set of type variables \(\alpha\) such that \(\sigma(
   \alpha) \not= \alpha\).
   \item[\labelitemi] \emph{compatible\((\sigma_1, \sigma_2)\)} %, where \(\sigma_1\) and \(\sigma_2\) are substitutions,
   tests the compatibility between \(\sigma_1\) and \(\sigma_2\).
%   \item[\labelitemi] Composition and application of substitutions are written using mathematical notations.
   \item[\labelitemi] \emph{mangle\((\Phi)\)}, where \(\Phi\) is a set of monomorphic formulae, returns the same set of formulae where all types have been mangled.
\end{enumerate}

\SetKwFunction{IterMono}{iterative\_monomorphisation}
\begin{figure}[t!]
%\begin{quote}
\begin{algorithm}[H]
\Fn(){\(\IterMono(\Phi)\)}{
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{To}{to}

   \SetKwData{Problem}{\(\Phi\)}\SetKwData{AllSubst}{\(S\)}

   \SetKwFunction{Init}{initialisation}\SetKwFunction{FStep}{formula\_mono\_step} 
   \SetKwFunction{TyVars}{type\_vars}\SetKwFunction{MonoSubst}{mono\_substs}
   \SetKwFunction{GenFormulae}{generate\_mono\_formulae}
   \SetKwFunction{Mangle}{mangle}

   \KwData{set \(\Phi\) of polymorphic formulae}
   \KwResult{set of monomorphic formulae}

   \BlankLine

   \((M_{\text{old}}, N_{\text{old}}) \leftarrow (\emptyset, \emptyset)\)\;
   \((M_{\text{new}}, N_{\text{new}}) \leftarrow \Init(\Problem)\)\;

   \AllSubst\(\leftarrow \emptyset\)\;

   \BlankLine

   \For{\(i = 1\) \To \textcolor{ourblueviolet}{\Loop}}{
      \((M_{\text{next}}, N_{\text{next}})\leftarrow(\emptyset,\emptyset)\)\;
      \ForEach{\(\varphi \in \Problem\)} {
         \((M_{\Delta}, N_{\Delta}, S_{\Delta})\leftarrow \FStep(\varphi, M_{\text{old}}, M_{\text{new}}, N_{\text{old}}(\varphi), N_{\text{new}}(\varphi))\)\;
         \(\AllSubst(\varphi)\leftarrow\AllSubst(\varphi)\cup S_{\Delta}\)\;
         \(M_{\text{next}}\leftarrow M_{\text{next}}\cup M_{\Delta}\)\;
         \(N_{\text{next}}(\varphi)\leftarrow N_{\text{next}}(\varphi)\cup N_{\Delta}\)\;
      }

      \((M_{\text{old}}, M_{\text{new}})\leftarrow (M_{\text{old}}\cup M_{\text{new}}, M_{\text{next}})\)\;
      \((N_{\text{old}}, N_{\text{new}})\leftarrow (N_{\text{old}}\cup N_{\text{new}}, N_{\text{next}})\)\;

   }

   \BlankLine

   \Return \(\Mangle(\GenFormulae(\Phi, S))\)
}
\end{algorithm}
%\end{quote}
\caption{Algorithm for iterative monomorphisation}
\label{iter_mono}
\end{figure}


The iterative monomorphisation algorithm is given in Figure~\ref{iter_mono}. It has three phases. The first phase applies a \emph{monomorphisation step} to each formula in \(\Phi\) until the user-set limit, \textcolor{ourblueviolet}{num\_loops}, is reached. This limit is the only bound necessary for the algorithm to terminate. We use the colour blue to identify bounds and code related to bounds. At the end of each of these iterations,\pagebreak[2]
the old and new type argument maps are updated with newly generated types. No new formulae are generated at this stage, only new type arguments and substitutions. Once these iterations are completed, the first phase is complete and the substitutions used to create new type argument tuples are passed to $\mathit{generate\_mono\_formulae}$ for the second phase. This is when the new formulae are generated. The third phase mangles the composite types of the newly monomorphised formulae. This allows targeting a simply typed logic with no support for $n$-ary type constructors.
%~\cite[Sections 4 and 5]{mono-trans}.
% Paper name is gt

\begin{figure}[t!]
%\begin{quote}
\begin{algorithm}[H]

   \Fn(){\(\FMonoStep(\varphi, M_{\text{old}}, M_{\text{new}}, N_{\text{old}}(\varphi), N_{\text{new}}(\varphi))\)}{

   \SetKw{Let}{let}

   \KwData{\begin{minipage}[t]{.8\textwidth}
     \strut polymorphic formula $\varphi$ \\
     old and new monomorphic type argument maps \(M_{\text{old}}, M_{\text{new}}\) \\
     old and new non-monomorphic type argument maps \(N_{\text{old}}(\varphi), N_{\text{new}}(\varphi)\)\strut
      \end{minipage}
   }
   \KwResult{\begin{minipage}[t]{.8\textwidth}
      \strut monomorphic type argument map \\
      non-monomorphic type argument map \\
      set of substitutions\strut
      \end{minipage}
   }
   \BlankLine

   %\(\TypeVars \leftarrow \TyVars(\varphi)\)\;

   \textcolor{ourblueviolet}{
   \(\MaxMono \leftarrow \Min(\Max(\MonoFloor, |M_{\text{old}}\cup M_{\text{new}}| \cdot \MonoMult), \MonoCap)\)\;
   \(\MaxPoly \leftarrow \Min(\Max(\PolyFloor, |N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi)| \cdot \PolyMult), \PolyCap)\)\;
   }

   \BlankLine

   \UsedSubst \(\leftarrow\emptyset\)\;

   $S' \leftarrow \SubstGen(M_{\text{new}}, N_{\text{new}}(\varphi))
   \cup \SubstGen(M_{\text{new}}, N_{\text{old}}(\varphi))
   \cup \SubstGen(M_{\text{old}}, N_{\text{new}}(\varphi))$\;
   \((M_\text{next}, N_\text{next}(\varphi)) \leftarrow (\emptyset, \emptyset)\)\;
   \ForEach{\(\sigma\in S'\)}{
   %\ForEach{\(f \in \text{dom}(N_\text{old}(\varphi)\cup N_\text{new}(\varphi))\)}{
   \ForEach{\((f \mapsto (\upsilon_1, \dots,\upsilon_n))\in N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi)\)}{
            \eIf{\(\TyVars(\upsilon_1, \dots, \upsilon_n) \subseteq \Domain(\sigma)\)}{
               \textcolor{ourblueviolet}{
               \uIf{\(|M_{\text{next}}| < \MaxMono\)}{
                  \textcolor{black}{
                  \(M_{\text{next}}(f)\leftarrow M_{\text{next}}(f)\cup\{(\sigma(\upsilon_1),\dots,\sigma(\upsilon_n))\kern-300mm\}\)\;
                  \UsedSubst \(\leftarrow \UsedSubst \cup\{\sigma\}\)\;}
               }
               \uElseIf{\(|N_{\text{next}}(\varphi)| \geq \MaxPoly\) }{
                  \(M_{\text{next}} \leftarrow M_{\text{next}}\setminus (M_{\text{old}} \cup M_{\text{new}})\)\;
                  \(N_{\text{next}}(\varphi)\leftarrow N_{\text{next}}(\varphi)\setminus (N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi))\kern-300mm\)\;
                  \Return \((M_{\text{next}}, N_{\text{next}}(\varphi), \UsedSubst)\)
               }}
            }{\textcolor{ourblueviolet}{
               \If{\(|N_{\text{next}}(\varphi)| < \MaxPoly\)}{ \textcolor{black} {
               \(N_{\text{next}}(\varphi)(f)\leftarrow N_{\text{next}}(\varphi)(f)\cup\{(\sigma(\upsilon_1),\dots,\sigma(\upsilon_n))\}\kern-300mm\)\;
               \(\UsedSubst \leftarrow \UsedSubst \cup\{\sigma\}\)\;
               }}
            }}
      }
   %}
   }

   \BlankLine

   \Return \((M_{\text{next}}\setminus (M_{\text{old}} \cup M_{\text{new}}), N_{\text{next}}(\varphi)\setminus (N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi)), \UsedSubst)\)
}

\end{algorithm}
%\end{quote}
\caption{Algorithm for formula monomorphisation step}
\label{mono_step}
\end{figure}


The formula monomorphisation algorithm is given in Figure~\ref{mono_step}. It forms the core of the process. Essentially, it computes new type argument tuples for a single formula. Type argument tuples are matched against each other to obtain a set of substitutions which is iterated over in the outermost loop. 
The separation of type argument tuples into old and new maps is used to ensure that only combinations involving at least one new map are considered. This avoids re-computing some matchings processed in previous iterations. %Not all such redundant computations can be avoided because the same substitution can be obtained from different matchings.
New tuples are obtained by applying
each substitution to each non-monomorphic type argument tuple such that at least one tuple component is instantiated by the substitution.


The total number of type argument tuples can increase cubically in the number of type argument tuples at each iteration and can therefore grow doubly exponentially in the number of iterations. We give a sketch of how such growth can occur for a single formula. If we assume that after \(k\) iterations, there are \(N_k\) type argument tuples in total divided evenly between monomorphic and non-monomorphic type argument tuples, then there can be up to \(\bigl(\frac{N_k}{2}\bigr)^2\) successful matches, yielding as many substitutions. Each substitution is then applied to each non-monomorphic type argument for a total of \(\bigl(\frac{N_k}{2}\bigr)^3\) possible new type argument tuples. If half of these new type argument tuples are monomorphic and the other half are non-monomorphic, then the next iteration will begin with \(N_{k+1} = N_k^3 \cdot 2^{-3}\) evenly split type argument tuples. Therefore, the total number of type argument tuples on the \(k\)th iteration can reach \(N_k = N_0^{3^k} \cdot 2^{\frac{-3^{k+2}+3}{2}}\).

   Depending on the shape and size of the input problem and the number of iterations performed, the doubly exponential growth may be problematic. Introducing bounds addresses this potential issue. The limit on the number of newly generated monomorphic type argument tuples is \(\min(\max(\MonoMult\cdot m, \MonoFloor), \MonoCap)\), where \(m\) is the total number of monomorphic type argument tuples. The components of this limit are
\begin{enumerate}
   \item \MonoCap, a %n absolute
   limit on the total number of new type argument tuples;
   \item \MonoMult, which is used to allow the total number of (monomorphic) type argument tuples to grow by a certain proportion of the current number \(m\) of monomorphic type argument tuples;
   \item \MonoFloor, which balances out \MonoMult, preventing \MonoMult from inhibiting new type argument tuple generation if \(m\) is too low.
\end{enumerate}

Similar bounds are used for the non-monomorphic type argument tuples:
The limit on the number of new non-monomorphic type argument tuples is \(\min(\max(\PolyMult\cdot n, \PolyFloor),\allowbreak \PolyCap)\), where \(n\) is the number of non-monomorphic type argument tuples associated with the current formula. An important difference with the monomorphic case is that \(n\) depends on the current formula being processed whilst \(m\) does not.
Both in the monomorphic and in the non-monomorphic case, the maximum number of newly generated type argument tuples is fixed per formula and per iteration.

The \emph{matches} function, which computes the substitutions used for generating new type arguments, is given in Figure~\ref{subst_gen}. Each symbol instance from \(N(\varphi)\) is matched against all corresponding symbol instances from \(M\).
For two such symbol instances, the types from the non-monomorphic type argument tuple are matched component-wise against the types from the monomorphic type argument tuple. The resulting substitutions are composed if they are compatible. In the algorithm, compatibility is checked by making sure the \textbf{foreach} loop has successfully iterated over all elements of the type argument tuple. If any substitutions are incompatible, the matchings are discarded. Since the composition of two compatible substitutions is commutative, the order of composition is irrelevant. The total number of substitutions generated is limited by \textcolor{ourblueviolet}{substitution\_cap}.

%\begin{figure}[t!]
%%\begin{quote}
%\begin{algorithm}[H]
%\SetKwFunction{SubstGen}{matches}
%\Fn(){\(\SubstGen(M, N(\varphi))\)}{
%   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}
%   \SetKwFunction{Success}{Success}\SetKwFunction{Compatible}{compatible}
%   \SetKwFunction{Match}{match}
%   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
%   \SetKw{Break}{break}
%
%   \KwData{\begin{minipage}[t]{.8\textwidth}
%      \strut monomorphic type argument map \(M\) \\
%      non-monomorphic type argument map \(N(\varphi)\)\strut
%      \end{minipage}
%   }
%   \KwResult{set of substitutions}
%   \BlankLine
%
%   \(S\leftarrow \emptyset\)\;
%
%   \BlankLine
%
%   \ForEach{\(f\mapsto (\upsilon_1, \dots,\upsilon_n)\in N(\varphi)\)}{
%      \ForEach{\( (\tau_1, \dots,\tau_n) \in M(f) \)}{
%         \(\sigma\leftarrow \{\}\)\;
%         \(i \leftarrow 1\)\;
%         \While{\(i \leq n\)}{
%            \eIf{\(\Match(\upsilon_i, \tau_i)\) has the form \(\Success(\sigma_i)\) \And \(\Compatible(\sigma, \sigma_i)\kern-300mm\)}{
%               \(\strut\sigma\leftarrow\sigma_i\circ\sigma\)
%            }
%            {\Break}
%
%            \(i\leftarrow i+1\)\;
%         }
%         
%         \If{\(i > n\)}{
%            \textcolor{ourblueviolet}{
%               \eIf{\(|S| < \SubstLimit\)}{
%                  \textcolor{black}{\(S\leftarrow S\cup \{\sigma\}\)\;}
%               }
%               {\Return \(S\)}
%            }
%         }
%      }
%
%   }
%
%   \BlankLine
%
%   \Return \(S\)\;
%
%}
%\end{algorithm}
%%\end{quote}
%\caption{Algorithm for match generation}
%\label{subst_gen}
%\end{figure}

\begin{figure}[t!]
%\begin{quote}
\begin{algorithm}[H]
\SetKwFunction{SubstGen}{matches}
\Fn(){\(\SubstGen(M, N(\varphi))\)}{
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}
   \SetKwFunction{Success}{Some}\SetKwFunction{Compatible}{compatible}
   \SetKwFunction{Match}{match}
   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
   \SetKw{Break}{break}

   \KwData{\begin{minipage}[t]{.8\textwidth}
      \strut monomorphic type argument map \(M\) \\
      non-monomorphic type argument map \(N(\varphi)\)\strut
      \end{minipage}
   }
   \KwResult{set of substitutions}
   \BlankLine

   \(S\leftarrow \emptyset\)\;

   \BlankLine
   \ForEach{\(f\mapsto (\upsilon_1, \dots,\upsilon_n)\in N(\varphi)\)}{
      \ForEach{\( (\tau_1, \dots,\tau_n) \in M(f) \)}{
               \textcolor{ourblueviolet}{
                  \If{\(|S| > \SubstLimit\)}
                     {\Return \(S\)}}
         \If{for all \(0 \leq i\leq n\), \(\Match(\upsilon_i, \tau_i) = \Success(\sigma_i)\)}
            {

               \If {\(\sigma_1,\dots,\sigma_n\) are compatible}{

                  \(\sigma\leftarrow\sigma_1\circ\dots\circ\sigma_n\)\strut

                     \textcolor{black}{\(S\leftarrow S\cup \{\sigma\}\)\;}
            }

            }

         
      }

   }

   \BlankLine

   \Return \(S\)\;

}
\end{algorithm}
%\end{quote}
\caption{Algorithm for match generation}
\label{subst_gen}
\end{figure}

\begin{figure}[t!]
%\begin{quote}
\begin{algorithm}[H]
\Fn(){\(\GenFormulae(\Phi, S)\)}{
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{To}{to}

   \SetKwData{NewFormulae}{\(\Psi\)}
   \SetKwData{Problem}{\(\Phi\)}\SetKwData{AllSubst}{\(S\)}
   \SetKwData{Limit}{max\_new\_formulae}

   \SetKwFunction{Init}{initialisation}\SetKwFunction{FStep}{formula\_mono\_step} 
   \SetKwFunction{TyVars}{type\_vars}\SetKwFunction{MonoSubst}{mono\_substs}
   \SetKwFunction{GenFormulae}{generate\_formulae}

   \KwData{\begin{minipage}[t]{.8\textwidth}
     \strut set \(\Phi\) of polymorphic formulae \\
     substitution map $S$\strut
     \end{minipage}}
   \KwResult{set of monomorphic formulae}

   \BlankLine

   \NewFormulae \(\leftarrow\emptyset\)\;

   \BlankLine

   \ForEach{\(\varphi\in\Phi\) \textbf{s.t.} $\varphi$ is non-monomorphic}{
      \ForEach{\(\sigma\in \MonoSubst(\AllSubst(\varphi), \TyVars{\(\varphi\)}, \emptyset, \{\})\)}{
         \textcolor{ourblueviolet}{
         \eIf{\(|\NewFormulae|<\Limit\)}{
            \textcolor{black}{
            \(\NewFormulae\leftarrow\NewFormulae\cup \{\sigma(\varphi)\}\)\;}
         }
         {\Return \NewFormulae}
      }}
   }

   \BlankLine

   \Return \NewFormulae
}
\end{algorithm}
%\end{quote}
\caption{Algorithm for monomorphic formula generation}
\label{gen_formulae}
\end{figure}


The various bounds presented here overlap to some extent. For instance, having at most \textcolor{ourblueviolet}{substitution\_cap} substitutions generated by \emph{matches} may be sufficient to curb the number of new type argument tuples, making the \textcolor{ourblueviolet}{\MonoCap}, \textcolor{ourblueviolet}{\MonoMult}, \textcolor{ourblueviolet}{\MonoFloor} triplet superfluous. Nonetheless every bound has uses. For example, problems that lead to few successful matches but many type argument tuples may benefit from a limit on the number of new type argument tuples whilst problems for which substitution generation is more combinatorially explosive may benefit from a limit on the number of generated substitutions.

\begin{figure}[t!]
%\begin{quote}
   \begin{algorithm}[H]

   \SetKwFunction{Compatible}{compatible}
   \SetKwFunction{MonoSubst}{mono\_substs}
   \SetKwFunction{Domain}{domain}
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{Stop}{stop}
   \SetKw{Let}{let}
   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

   \Fn(){\(\MonoSubst(S, V, S_{\text{res}}, \sigma)\)}{

   \KwData{\begin{minipage}[t]{.8\textwidth}
     \strut set \(S\) of substitutions \\
     set \(V\) of type variables \\
     \strut set \(S_{\text{res}}\) of substitutions \\
     substitution \(\sigma\)\strut
      \end{minipage}
   }

   \KwResult{set of substitutions}
   \BlankLine

   \eIf{\(V = \emptyset\)}{
    \Return \(S_{\text{res}}\cup\{\sigma\}\)\;%}
   }
   {
      \Let \(\alpha \) \textbf{s.t.} \(\alpha\in V\)\;
      \ForEach{\(\sigma_{\negvthinspace\Delta}\in S\) \textbf{s.t.} \(\alpha\in\Domain(\sigma_{\negvthinspace\Delta})\) \And \(\Compatible(\sigma,\sigma_{\negvthinspace\Delta})\)}{
         \textcolor{ourblueviolet}{
         \eIf{\(|S_{\text{res}}|<\MonoSubstsLimit\)}{
            \textcolor{black}{
            \(S_{\text{res}}\leftarrow \MonoSubst(S, V\setminus\Domain(\sigma_{\negvthinspace\Delta}), S_{\text{res}}, \sigma_{\negvthinspace\Delta}\circ\sigma)\)\;}
         }
         {\Return \(S_{\text{res}}\)}}
      }
      \Return \(S_{\text{res}}\)\;
   }
   }


\end{algorithm}
%\end{quote}
\caption{Algorithm for monomorphising substitution generation}
\label{mono_substs}
\end{figure}

Once all monomorphisation iterations have been completed, we are left with a set of the substitutions that have been used to generate new type arguments. The last phase uses this set to instantiate the type variables in the input problem's non-monomorphic formulae. In the presence of bounds, the order in which the elements of \(S\) are traversed affects the formulae resulting from the last phase. %As we will discuss in Section~\ref{param_opti}, the best results were obtained when substitutions generated in the same iteration are grouped together.

The \emph{generate\_mono\_formulae} function is given in Figure~\ref{gen_formulae}.
It generates monomorphising substitutions and applies them to the polymorphic formulae of the input problem that they instantiate.
A substitution \(\sigma\) is \emph{monomorphising} for a formula \(\varphi\) if \(\sigma(\varphi)\) is monomorphic.
Since the substitutions are monomorphising relative to the formula they are applied to, the resulting formulae will be monomorphic. The \textcolor{ourblueviolet}{max\_new\_formulae} bound is used to control the total number of new formulae. It overlaps with \textcolor{ourblueviolet}{max\_substs} but can be useful to set an absolute limit on the size of the final problem.
%In the Zipperposition implementation, this bound is one of the more important ones as the performance of the E prover can be significantly affected by the number of formulae it is given.

To monomorphise a polymorphic formula, we first compute its {monomorphising substitutions} using the \emph{mono\_substs} function given in Figure~\ref{mono_substs}.
Such substitutions are computed using a recursive function. Given a set \(V\) of type variables and a set \(S(\varphi)\) of substitutions, it selects a substitution \(\sigma_{\negvthinspace\Delta}\) from \(S(\varphi)\) that instantiates at least one of the type variables in \(V\). It is important that \(\sigma_{\negvthinspace\Delta}\) be compatible with \(\sigma\) so that they can be composed and the function recursively called to instantiate the remaining type variables.

The Zipperposition implementation of the \emph{mono\_substs} function uses a map from type variables to substitutions instead of a set to filter the relevant substitutions from \(S\) efficiently. The \textcolor{ourblueviolet}{max\_substs} bound exists for two main reasons:
\begin{enumerate}
   \item The iterative monomorphisation algorithm can generate up to \textcolor{ourblueviolet}{max\_substs} new monomorphic formulae per initial polymorphic formula. Generating an excessive number of new formulae can overwhelm the prover. The final number of output formulae is limited to at most \(|\Phi|\cdot \text{\textcolor{ourblueviolet}{max\_substs}}\).
   \item The \emph{mono\_substs} function is the algorithm's most combinatorially explosive part. For a formula \(\varphi\), if \(S(\varphi)\) contains \(n\) substitutions that each instantiate exactly one of \(v\) %different
type variables, up to \(n^v\) monomorphising substitutions may be generated. Recall that the total number of type argument tuples used to generate \(S(\varphi)\) can be doubly exponential in the number of loop iterations. The starting \(n\) may therefore already be very large.
\end{enumerate}
%[This function can be thought of as exploring the tree of all possible monomorphising substitutions, \(S_{\text{res}}\) would represent the leaves that have already been visited and \(\sigma\) would represent the current node of the tree.]

\section{Detailed example}

To illustrate the low level version of the iterative algorithm, we consider the following (admittedly contrived) initial problem:
\begin{itemize}
   \item[\(\langle1\rangle\)] \(\sym{p}\langle \ty{int}, \ty{nat}\rangle(-1, 3) \land \sym{p}\langle \ty{int}, \ty{int}\rangle(-1, -2)\)
   \item[\(\langle 2\rangle\)] \(\forall x: \alpha{,}\; y:\ty{list}(\alpha){,}\; z: \beta{.}\; \sym{p}\langle \ty{list}(\alpha), \alpha\rangle(y, x) \land \sym{p}\langle \alpha, \alpha \rangle(x, x) \land \sym{p}\langle \alpha, \beta\rangle(x, z)\)
\end{itemize}
%
\(M_{\text{new}}\) is initialised with \(\{\sym p\mapsto (\ty{int}, \ty{nat}); \sym p\mapsto (\ty{int}, \ty{int})\}\) and \(N_{\text{new}}\) with \(\{\langle 2\rangle\mapsto \{\sym p\mapsto (\ty{list}(\alpha), \alpha); \sym p\mapsto (\alpha, \alpha); \sym p\mapsto (\alpha, \beta)\}\}\). Then we enter the main loop (assuming \Loop is at least 1). We iterate over each formula and call \FStep for each of them. Nothing happens for formula \(\langle1\rangle\) because it contains no type variables. For formula \(\langle2\rangle\), \(M_{\text{new}}\) and \(N_{\text{new}}(\langle2\rangle)\) are passed as argument to \SubstGen.

The three non-monomorphic type argument tuples are matched against their monomorphic counterparts in \(M_{\text{new}}\):
\begin{itemize}
   \item \((\ty{list}(\alpha), \alpha)\) fails in both cases because \(\ty{list}(\alpha)\) fails to match against \ty{int}.
   \item \((\alpha, \alpha)\) fails to match against \((\ty{int}, \ty{nat})\) because the substitutions resulting from the match of the first and second element of the tuple are incompatible. The second match is successful and yields the substitution \(\sigma_1 = \{\alpha \mapsto \ty{int}\}\)
   \item \((\alpha, \beta)\) succeeds in both cases and generates the substitutions \(\sigma_2 = \{\alpha \mapsto \ty{int}, \beta \mapsto \ty{int}\}\) and \(\sigma_3 = \{\alpha \mapsto \ty{int}, \beta \mapsto \ty{nat}\}\).
\end{itemize}

Then \SubstGen returns, and the substitutions are used to generate new type argument tuples. Each substitution is applied to the type arguments of the function symbols of formula \(\langle2\rangle\) because they are the only function symbols with non-monomorphic type arguments.
The table below summarises the situation:
\begin{table}
\centering\begin{tabular}{@{}l*{3}{>{\centering\arraybackslash}p{6em}}@{}}
   \toprule
   & \(\sigma_1\) &\(\sigma_2\)&\(\sigma_3\)\\
   \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(l){4-4} 
   \((\ty{list}(\alpha), \alpha)\)&\((\ty{list}(\ty{int}), \ty{int})\)& \((\ty{list}(\ty{int}), \ty{int})\) & \((\ty{list}(\ty{int}), \ty{int})\) \\
   \((\alpha, \alpha)\) &\((\ty{int}, \ty{int})\)&\((\ty{int}, \ty{int})\) &\((\ty{int}, \ty{int})\)\\
   \((\alpha, \beta)\)  &\((\ty{int}, \beta)\)&\((\ty{int}, \ty{int})\) &\((\ty{int}, \ty{nat})\)\\
    \bottomrule
\end{tabular}
\end{table}

With a very small and simple initial problem, there are already up to nine new type arguments tuples generated at this step in the first iteration alone, although only four are unique. Once the new type argument tuples are added to their respective maps, a new iteration is begun. We only consider one iteration and continue to the next phase of the algorithm.

The next function to be called is \GenFormulae. It iterates over all non-monomorphic formulae of the initial problem; in our case, this will only be \(\langle2\rangle\). The set of type variable tuples of \(\langle2\rangle\) is passed to \MonoSubst along with the set of all previously generated substitutions.

First, we instantiate \(\alpha\), the first type variable of \(\langle2\rangle\). If \(\sigma_1\) is selected to instantiate \(\alpha\), both \(\sigma_2\) and \(\sigma_3\) will in turn be selected to instantiate \(\beta\). This will generate two monomorphising substitutions, \(\sigma_1 \circ \sigma_2 = \sigma_2\) and \(\sigma_1 \circ \sigma_3 = \sigma_3\), which are added to the set of monomorphising substitutions \(S_{\text{res}}\). Now \(\sigma_2\) is selected. It simultaneously instantiates \(\alpha\) and \(\beta\). Here, \(\sigma_2\) is already in \(S_{\text{res}}\) and is therefore ignored, and \(\sigma_3\) is treated similarly. No more than \SubstLimit monomorphising substitutions can be generated in this way.

The monomorphising substitutions have been generated. We only need to apply them to the formula they monomorphise. This is repeated for all non-monomorphic formulae or until \Limit is reached. The ordering of formulae will impact the output problem in the latter case. For some larger input problems, \MonoSubst could be sufficiently explosive to only allow a handful of different formulae to be monomorphised. The ability to set \SubstLimit independently can help avoid this issue. 

Finally, if the target language supports only nullary type construtors, the types of all monomorphic formulae, both new and old, are mangled.
%This step is unnecessary if the target language allows type constructors.
In our example, two new monomorphic formulae are generated. The algorithm outputs
\begin{enumerate}
   \item[\(\langle1\rangle\)] \(\sym{p}\langle \ty{int}, \ty{nat}\rangle(-1, 3) \land \sym{p}\langle \ty{int}, \ty{int}\rangle(-1, -2)\)
   \item[\(\langle3\rangle\)] \(\forall x: \ty{int}{,}\; y:\ty{list}(\ty{int}){,}\; z: \ty{int}{.}\; \begin{aligned}[t]
     & \sym{p}\langle \ty{list}(\ty{int}), \ty{int}\rangle(y, x) \land \sym{p}\langle \ty{int}, \ty{int} \rangle(x, x) \land {} \\[-\jot]
     & \sym{p}\langle \ty{int}, \ty{int}\rangle(x, z)\end{aligned}\)
   \item[\(\langle4\rangle\)] \(\forall x: \ty{int}{,}\; y:\ty{list}(\ty{int}){,}\; z: \ty{nat}{.}\; \begin{aligned}[t]
     & \sym{p}\langle \ty{list}(\ty{int}), \ty{int}\rangle(y, x) \land \sym{p}\langle \ty{int}, \ty{int} \rangle(x, x) \land {} \\[-\jot]
     & \sym{p}\langle \ty{int}, \ty{nat}\rangle(x, z)\end{aligned}\)
\end{enumerate}

% target page number: 2-4
\section{Evaluation}
\label{sec:evaluation}

The monomorphisation algorithm is parametrised by many bounds. The first part of the evaluation process seeks appropriate values for these bounds. The second part compares the performance of Zipperposition without E and with the new monormorphising E backend on polymorphic problems. The third part compares the performance of different provers on polymorphic problems and their monomorphised counterparts.

The benchmarks are taken from version 8.2.0 of the TPTP library~\cite{tptp}. The library contains 1765 problems in TF1 and TH1, corresponding respectively to first and higher order logic with rank~1 polymorphism. Because Zipperposition does not support reasoning with real numbers, we removed all problems that include them. In total, our benchmark suite contains 1534 polymorphic problems. We chose as a measure of success for a given prover (or prover configuration) the number of problems
that could be solved by the prover in at most 30~s
%(including monomorphisation when relevant)
per problem with a single thread.
Our raw evaluation data is available online.%
\footnote{\url{https://zenodo.org/records/14881532}}

%This corresponds to the default time limit in Sledgehammer.

\paragraph{\upshape\bfseries Parameter optimisation.}

Each bound of the monomorphisation process represents a tradeoff: a higher bound allows for a more exhaustive instantiation of type variables but takes more time. Since we cannot test all possible combinations of values for all bounds to find the best compromise between completeness and speed,
we group closely related bounds together and test combinations of values for the bounds in these groups. Once we find the best performing set of values for a group, we assign these values to the corresponding bounds as we begin the search for the next group. If several groups result in the same number of proved problems, we select the most constraining values. Winning entries are shown in bold in Tables \ref{mono_ty_args}~to~\ref{e_settings}.

To detect if overfitting took place, we carried out the part of the evaluation related to parameter optimisation and all preliminary evaluations on 500 randomly chosen problems out of the 1534 selected problems. We carried out the rest of the evaluations on the remaining 1034 problems.

Before finding values to assign to the bounds of the monomorphisation algorithm, we must choose which base options to run Zipperposition with. The prover has a portfolio mode with several configurations. Because the space of possible base configurations is too large to evaluate exhaustively, we evaluated, in a preliminary experiment, all portfolio configurations that called E against our benchmark suite of 500 problems, but we disabled E.
Our preliminary evaluation found that the so-called \verb|40_b.comb| configuration performed best by proving 131 problems.
This configuration became the base configuration, which we used as a basis to evaluate the monomorphisation options.

We conducted additional informal evaluations on the 500 problems to find appropriate default values and test ranges for the monomorphisation bounds. We started the option evaluation process with the base configuration and the following default values for monomorphisation bounds and parameters for E:
%
\begin{minipage}[t]{.5\textwidth}
\vskip0\topsep

\begin{itemize}
   \item \PolyCap: \(\infty\)
   \item \PolyMult: \(1\)
   \item \PolyFloor: \(50\)
   \item substitution ordering: separation
   \item \SubstLimit: \(\infty\)
   \item \MonoSubstsLimit: \(10\)
\end{itemize}

\vskip0\topsep
\end{minipage}\begin{minipage}[t]{.5\textwidth}
\vskip0\topsep

\begin{itemize}
   \item \Limit: \(2000\)
   \item new formulae limit multiplier: \(0\)
   \item monomorphisation timeout: \(20\)
   \item \Loop: \(4\)
   \item E timeout: \(30\)
   \item E call point: \(0\)
\end{itemize}

\vskip0\topsep
\end{minipage}
%
The initial values for the \MonoCap, \MonoMult and \MonoFloor options are irrelevant because the options' values are set when computing Table~\ref{mono_ty_args}.% and used for subsequent tables.

Table~\ref{mono_ty_args} groups bounds that control the maximum number of newly generated monomorphic type arguments per formula and per iteration. The limit on newly generated type arguments is determined by three components that form a natural group of bounds. The table shows that generating no new monomorphic type arguments seems to be the best approach. This result may seem counterintuitive, but it is possible to monomorphise formulae without generating monomorphic type arguments. This is because non-monomorphic type argument generation can generate substitutions that instantiate one or more type variables, and it is these substitutions that are used to monomorphise formulae.

\begin{table}[t!]
\caption{Evaluation of bounds for monomorphic type argument generation}

\medskip

\centering\begin{tabular}{@{}l*{12}{>{\centering\arraybackslash}p{2.5em}}@{}}
   \toprule
   & &&& \multicolumn{6}{c}{cap} \\
   & \multicolumn{4}{c}{500} &\multicolumn{4}{c}{1000} & \multicolumn{4}{c}{\(\infty\)}\\
   \cmidrule(l){2-13}
   & &&& \multicolumn{6}{c}{floor} \\
   \multirow{1}{2.5em}{mult} & 0 & 50 & 100 & 200& 0 & 50 & 100 & 200& 0 & 50 & 100 & 200\\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(l){10-13} 
    0       &\bf{178}& 161 & 161 & 156 & 178 & 160 & 160 & 156 & 178 & 161 & 160 & 156 \\
    1          & 155 & 155 & 155 & 158 & 153 & 154 & 154 & 156 & 154 & 154 & 155 & 155 \\
    2          & 154 & 154 & 153 & 154 & 153 & 153 & 154 & 152 & 154 & 153 & 154 & 154 \\
    \(\infty\) & 153 & 154 & 153 & 155 & 155 & 153 & 154 & 156 & 159 & 160 & 161 & 161 \\
    \bottomrule
\end{tabular}
\label{mono_ty_args}
\end{table}

\looseness=-1
Table~\ref{nmon_ty_args} is similar to Table~\ref{mono_ty_args} except that it evaluates the bounds limiting the number of new \emph{non-}monomorphic type arguments. The bound values are lower because we found non-monomorphic type arguments to be combinatorially explosive in preliminary evaluations. The table confirms that non-monomorphic type argument generation drives the creation of useful non-mono\-morphic formulae. This is indicated by the very low number of problems solved when no new non-monomorphic type arguments are allowed. Performance of the monomorphisation algorithm seems to plateau for some ranges of values and drops off beyond.
%TODO check that 125 is what we get if we just run Zipperposition for 10~s (maybe with all additional problems that are easily monomorphised)

\begin{table}[t!]
\caption{Evaluation of bounds for non-monomorphic type argument generation}

\medskip

\centering\begin{tabular}{@{}l*{12}{>{\centering\arraybackslash}p{2.5em}}@{}}
   \toprule
   & &&& \multicolumn{6}{c}{cap} \\
   & \multicolumn{4}{c}{500} &\multicolumn{4}{c}{1000} & \multicolumn{4}{c}{\(\infty\)}\\
   \cmidrule(l){2-13}
   & &&& \multicolumn{6}{c}{floor} \\
   \multirow{1}{3em}{mult} & 0 & 10 & 50 & 100& 0 & 10 & 50 & 100& 0 & 10 & 50 & 100\\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(l){10-13} 
    0         &125&\bf{184}& 182 & 177 & 125 & 184 & 182 & 177 & 125 & 184 & 182 & 177 \\
    0.5        & 176 & 184 & 182 & 177 & 176 & 184 & 182 & 177 & 176 & 184 & 182 & 177 \\
    1          & 182 & 181 & 178 & 177 & 182 & 181 & 178 & 177 & 182 & 181 & 178 & 177 \\
    \(\infty\) & 173 & 174 & 174 & 174 & 174 & 174 & 173 & 173 & 125 & 125 & 125 & 125 \\
    \bottomrule
\end{tabular}
\label{nmon_ty_args}
\end{table}

%The substitution generation phase occurs once all type arguments have been generated. The bounds limiting the number of new substitutions and the number of monomorphising substitutions per formula are directly related through the role they play in the construction of monomorphising substitutions. The substitution ordering heuristic has a significant impact on monomorphising substitution generation. The ``age'' ordering of substitution orders substitutions generated in earlier iterations are ordered first. The ``random'' ordering randomly shuffles substitutions. Finally, the ``separation'' ordering separates the substitutions into different sets depending on which iteration they were generated in and generates monomorphising substitutions from each of these sets independently. Table \ref{subst_gen_table} shows that the values of bounds limiting the number of substitutions generated has very little impact on overall performance contrary to the ordering heuristic.
The substitution generation phase occurs once all type arguments have been generated. The bound limiting the number of monomorphising substitutions per formula is directly related to the ordering which dictates how such monomorphising substitutions are generated. The %substitution ordering
heuristic greatly affects monomorphising substitution generation. The `age' ordering of substitution orders substitutions generated in earlier iterations first. The `random' ordering randomly shuffles substitutions. Finally, the `separation' ordering separates the substitutions into groups of substitutions generated in the same iteration and generates monomorphising substitutions from each of these groups independently. Table \ref{subst_gen_table} shows that the values of bounds limiting the number of monomorphising substitutions only seem to affect performance when the `separation' heuristic is used.
% TODO find a better term than "separation heuristic" maybe separation ?

\begin{table}[t!]
\caption{Evaluation of bounds for substitution generation}

\medskip

\centering\begin{tabular}{@{}l*{3}{>{\centering\arraybackslash}p{6em}}@{}}
   \toprule
   & \multicolumn{3}{c}{substitution ordering} \\
   \multirow{1}{6em}{mono subst} & age & random & separation\\
   \cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
   2  & 161 & 178 & 175 \\
   5  & 161 & 178 & 180 \\
   7  & 161 & 178 & 182 \\
   10 & 161 & 178 &\bf{184} \\
   \bottomrule
\end{tabular}
\label{subst_gen_table}
\end{table}


Table \ref{pb_size} groups the bounds related to the size of the output problem to be passed to the E prover. The absolute limit is the maximum number of formulae passed to E. The multiplier limits the total number of newly generated formulae based on the problem's initial number of formulae. We find that the E prover tends to perform better when given a limited number of formulae.

\begin{table}[t!]
\caption{Evaluation of bounds directly related to the size of the output problem}

\medskip

\centering\begin{tabular}{@{}l*{4}{>{\centering\arraybackslash}p{3em}}@{}}
   \toprule
   & \multicolumn{4}{c}{formula multiplier}\\
   \multirow{1}{5.2em}{formula cap} & 1 & 2 & 3 & \(\infty\)\\
   \midrule
   500       &\bf{184}& 184 & 184 & 183 \\
   2000         & 184 & 184 & 184 & 184 \\
   \(\infty\)   & 168 & 178 & 183 & 125 \\
   \bottomrule
\end{tabular}
\label{pb_size}
\end{table}

For larger problems, the monomorphisation algorithm may time out despite the bounds. In these cases neither Zipperposition nor E will have had a chance to try to solve the problem. To avoid this, a timer can interrupt the monomorphisation algorithm, after which Zipperposition resumes normal operation. Table~\ref{mono_time} tests the amount of time that is allocated to monomorphisation against the number of iterations of the monomorphisation algorithm. Neither parameter seems to substantially affect the algorithm's performance.

\begin{table}[t!]
\caption{Evaluation of parameters related to the depth of monomorphisation}

\medskip

\centering\begin{tabular}{@{}l*{4}{>{\centering\arraybackslash}p{2.5em}}@{}}
   \toprule
   & \multicolumn{4}{c}{mono time} \\
   \multirow{1}{6em}{num.\ loops} & 5 & 10 & 20 & 30\\
   \midrule
   1     & 183 & 184 & 183 & 183  \\
   2  &\bf{186}& 186 & 186 & 185  \\
   3     & 186 & 186 & 186 & 185  \\
   4     & 186 & 186 & 186 & 185  \\
   5     & 185 & 185 & 185 & 184  \\
   \bottomrule
\end{tabular}
\label{mono_time}
\end{table}

Table \ref{e_settings} shows the impact of the options with which we call the E prover.
The point at which Zipperposition interrupts its normal operation and begins the monomorphisation process is determined by the `E call point' parameter. It is expressed as a fraction of the total time allotted to Zipperposition.
The E timeout (in seconds) limits how long E is run before being interrupted, at which point Zipperposition resumes normal operation. The longer Zipperposition runs before E is invoked, the more formulae are generated, and the more combinatorially explosive iterative monomorphisation is. This likely explains the poor performance for greater values of the E call point.

\begin{table}[t!]
\caption{Evaluation of parameters related to the E prover}

\medskip

\centering\begin{tabular}{@{}l*{4}{>{\centering\arraybackslash}p{3em}}@{}}
   \toprule
   & \multicolumn{4}{c}{E call point} \\
   \multirow{1}{5em}{E timeout} & 0 & 0.1 & 0.2 & 0.3\\
   \midrule
   2      & 180 & 143 & 132 & 124 \\
   5   &\bf{185}& 142 & 134 & 125 \\
   10     & 184 & 143 & 132 & 125 \\
   20     & 184 & 137 & 133 & 125 \\
   30     & 182 & 133 & 134 & 125 \\
   \bottomrule
\end{tabular}
\label{e_settings}
\end{table}

\paragraph{\upshape\bfseries E as a Zipperposition backend.}

\begin{table}[t!]
\caption{Evaluation of Zipperposition without E vs.\ with E}

\medskip

\centering\begin{tabular}{@{}l*{3}{>{\centering\arraybackslash}p{6em}}@{}}
   \toprule
   & without E & with E & union \\
   \midrule
   500 problem suite   & 160 & 198 & 207 \\ % -9 +47
   1034 problem suite & 337 & 410 & 434 \\ % -24 +97
   \bottomrule
\end{tabular}
\label{zipp_eval}
\end{table}

We compare the performance of two instances of Zipperposition. By default, Zipperposition may call E as a backend when given a monomorphic problem~\cite{vukmirovic-et-al-2021}. The first instance is run in the portfolio mode \verb|portfolio.sequential.py|, which attempts to prove the problem with various configurations tried in succession. Since all given problems are non-monomorphic, these configurations can never invoke E as a backend, this instance is therefore labeled `without E'. The second instance is a modification of the \verb|portfolio.sequential.py| file where each configuration is modified analogously to \verb|40_b.comb| with the options obtained in the previous evaluation phase. This instance can successfully call E as a backend because it is able to provide E with a monomorphised problem.
Each of the two instances is evaluated on the set of the 500 previously used problems, and the set of the remaining 1034 problems is evaluated separately. The proportion of problems successfully solved on the 500 and 1034 problem suites are similar, suggesting that no overfitting took place during the option optimisation phase.

Table \ref{zipp_eval} shows that the use of E as a backend markedly improves the performance of Zipperposition. It is not a strict improvement, since some problems are solved without E and not with E.


\paragraph{\upshape\bfseries Monomorphisation as a preprocessor.}

\begin{table}[t!]
\caption{Evaluation of native polymorphism vs.\ monomorphisation}

\medskip

\centering\begin{tabular}{@{}l*{3}{>{\centering\arraybackslash}p{6em}}@{}}
   \toprule
   & Native & Mono & Union \\
   \midrule
   E              & -- & 340 & 340 \\
   Leo-III with E &  157 & 231 & 274 \\ 
   Zipperposition & 339 & 351 & 404 \\%[1.5\jot]
%   Total          & 0 & 0 & 0 \\
   % Satallax       &  & 0 & 0 \\ % doesn't understand negated conjectures
   %Leo-III &  68 with cvc4 & 0 & 0 \\ % same as without anything for the native case
   %Vampire & 0 & 0 & 0 \\ % Vampire's parser fails on too many polymorphic problems (about 1/3 of them)
   \bottomrule
   \label{native_vs_mono_eval}
\end{tabular}
\end{table}

To evaluate the usefulness of iterative monomorphisation as an alternative to native polymorphism, two competitive higher order polymorphic provers were run on the 1034 problem suite. We chose Leo-III and Zipperposition. Unfortunately we needed to exclude Vampire because of parsing issues.
%Vampire failed to parse a significant number of the benchmarks problems.
The fix was unavailable for Vampire's higher order branch at the time of the evaluation.

Table~\ref{native_vs_mono_eval} shows the results.
The monomorphisation approach is evaluated in two steps. First, each problem is monomorphised using the options obtained from the first evaluation phase except for the monomorphisation timeout option, which is increased to 30~s. For 149~problems, monomorphisation times out. Second, each prover is run on the remaining monomorphised problems, and the results are tallied in the `Mono' column. In addition to the polymorphic provers used in the `Native' tests, the monomorphic prover E is run on the monomorphised problems to provide an additional point of comparison. Instead of running each prover for 30~s on the monomorphised problems, the monomorphisation time (rounded up to the nearest second) is subtracted to compare fairly against the `Native' column, which does not have a similar preprocessing phase.

Despite the monomorphisation timeouts, monomorphisation is more effective than Leo-III's and Zipperposition's native polymorphism on the benchmarks.


% target page number: 0.5-1
%\section{Related work}
%\label{sec:related-work}
%
%  * monomorphisation:
%    Isabelle for \textit{smt} tactic (Böhme), \textit{metis}, Sledgehammer
%  * a precursor for this work is the \verb|POLY_ASSUME_TAC| preprocessor of
%    MESON for HOL Light. It is unfortunately not documented beyond the comment
%    ``Push duplicated copies of poly theorems to match existing assumptions''
%    but it appears to perform at least partial monomorphisation.
%
%  * alternative: encode polymorphism
%    * many approaches to encode monomorphic and polymorphic types, starting
%      with Enderton~\cite{xxx}, Stickel~\cite{xxx}, and Wick and McCune
%     ~\cite{xxx}
%    * Blanchette et al.~~\cite{xxx} exploit ``monotonicity'' to erase type
%      information
%    * see Blanchette et al.~~\cite[Section~9]{xxx} for a more detailed coverage
%      of encodings of polymorphism
%    
%%\li{https://www.tcs.ifi.lmu.de/mitarbeiter/jasmin-blanchette/enc_types_article.pdf}

% target page number: 0.5-1
\section{Conclusion}
\label{sec:conclusion}

We described an algorithm for iteratively instantiating polymorphic types to
produce monomorphic problems as a preprocessor. Our primary motivation was to
improve the success rate of Zipperposition and its monomorphic E backend, and
indeed our evaluation shows a clear improvement. We also saw that even with
automatic provers that support polymorphism, iterative monomorphisation is a
better alternative in practice.

\looseness=-1
We see the following avenues for future work. First, iterative monomorphisation
blindly enumerates candidate instantiations, without exploiting any knowledge
about the logical structure of the formulae in which symbols occur. For
example, a lemma $\sym{p}\langle\alpha\rangle$ cannot be used to prove the
conjecture $\lnot \sym{p}\langle\ty{nat}\rangle$ because of the incompatible
polarities, but our algorithm instantiates $\alpha$ with $\ty{nat}$ regardless.
Second, some automatic provers as well as tools such as Sledgehammer include
relevance filters that heuristically select a subset of the available axioms;
filters such as MePo~\cite{meng-paulson-2009} and SInE~\cite{hoder-voronkov-2011} are iterative and could be interleaved with
monomorphisation. Third, although one would expect native implementations of
polymorphism to outperform any preprocessor, currently this is not the case, suggesting that there is considerable room for improvement on the native front.

\begin{credits}
   \subsubsection{Acknowledgements.}

   We thank Sascha Böhme for fruitful discussions.
   We thank Jannis Limperg, Mark Summerfield, and the peer reviewers for suggesting textual improvements.
   This research is co-funded by the European Union (ERC, Nekoka, 101083038). Views and opinions expressed are however those of the authors only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them.
\end{credits}

\bibliographystyle{splncs04}
\bibliography{citations}

\end{document}
