\documentclass[]{ceurart}

\usepackage{soul}
\usepackage[dvipsnames]{xcolor}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{array}
\usepackage{multirow}
\usepackage[noend]{algorithm2e}
\usepackage{amsmath}
\usepackage{enumitem}

\SetNlSty{bfseries}{\color{black}}{}

\lstset{breaklines=true}

\newcommand\ty[1]{\textsf{#1}}
\newcommand\sym[1]{\textsf{#1}}
\newcommand\var[1]{\mathit{#1}}

%% TYPESETTING: hacks
\newcommand\medrightarrow{\mathrel{{{\color{black}\relbar}\kern-0.9ex\rlap{\color{white}\ensuremath{\blacksquare}}\kern-0.9ex}\joinrel{\color{black}\rightarrow}}}
\newcommand\medleftarrow{\mathrel{{\color{black}\leftarrow}\kern-0.9ex\rlap{\color{white}\ensuremath{\blacksquare}}\kern-0.9ex\joinrel{{\color{black}\relbar}}}}
\newcommand\medleftrightarrow{\mathrel{\leftarrow\kern-1.685ex\rightarrow}}
\newcommand\Medrightarrow{\mathrel{{{\color{black}\Relbar}\kern-0.9ex\rlap{\color{white}\ensuremath{\blacksquare}}\kern-0.9ex}\joinrel{\color{black}\Rightarrow}}}
\newcommand\Medleftrightarrow{\mathrel{\Leftarrow\kern-1.685ex\Rightarrow}}

\def\negvthinspace{\kern-0.083333em}
\def\vthinspace{\kern+0.083333em}

\newdefinition{definition}{Definition}
\newdefinition{example}[definition]{Example}

\setlist[itemize]{topsep=5pt, itemsep=0pt}
\setlist[enumerate]{topsep=5pt, itemsep=0pt}

% algo2e package
\SetFuncSty{textit}
\SetFuncArgSty{text}
\SetArgSty{text}
\SetDataSty{text}

\DontPrintSemicolon

% some keywords
\SetKwFunction{GenFormulae}{generate\_mono\_formulae}
\SetKw{ST}{such that}

\SetKwData{MonoCap}{\textcolor{ourblueviolet}{mono\_cap}}
\SetKwData{MonoMult}{\textcolor{ourblueviolet}{mono\_mult}}
\SetKwData{MonoFloor}{\textcolor{ourblueviolet}{mono\_floor}}
\SetKwData{PolyCap}{\textcolor{ourblueviolet}{nonm\_cap}}
\SetKwData{PolyMult}{\textcolor{ourblueviolet}{nonm\_mult}}
\SetKwData{PolyFloor}{\textcolor{ourblueviolet}{nonm\_floor}}
\SetKwData{MaxMono}{\textcolor{ourblueviolet}{max\_mono\_args}}
\SetKwData{MaxPoly}{\textcolor{ourblueviolet}{max\_nonm\_args}}
\SetKwData{TypeVars}{type\_variables}
\SetKwData{UsedSubst}{\(S\)}

\SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{Stop}{stop}

\SetKwFunction{Max}{max}\SetKwFunction{Min}{min}
\SetKwFunction{Domain}{subst\_domain}\SetKwFunction{Len}{len}
\SetKwFunction{SubstGen}{matches}\SetKwFunction{TyVars}{type\_variables}
\SetKwFunction{FMonoStep}{formula\_mono\_step}
\SetKwProg{Fn}{Function}{}{end}\SetKwFunction{FRecurs}{FnRecursive}%
\newcommand{\forcond}{$i=0$ \KwTo $n$}

\definecolor{ourblueviolet}{HTML}{0071BC}
\definecolor{grey}{rgb}{0.8,0.8,0.8}
\definecolor{algoColorKeyword}{named}{grey}
\makeatletter
% Block with a vertical line
\renewcommand{\algocf@Vsline}[1]{%
   \strut\par\nointerlineskip%
   \algocf@bblockcode%
   \algocf@push{\skiprule}%
   \hbox{{\color{algoColorKeyword}\vrule}%
      \vtop{\algocf@push{\skiptext}%
      \vtop{\algocf@addskiptotal\advance\hsize by -\skiplength #1}}%
   }%
   \algocf@pop{\skiprule}%
   \algocf@bblockcode%
}
\makeatother

\begin{document}

\copyrightyear{2024}
\copyrightclause{Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)}

\conference{Submitted draft} % TODO update

% TODO, at the end check the following
%   - formulas -> formulae
%   - clause -> formula
%   - terms in ``xxx'' -> \emph{xxx}
%   - monomorphization -> monomorphisation
%   - higher-order -> higher order
%   - TH1 with ugly 1
%   - correctly spelled TPTP, Leo-III, Zipperposition, E, Vampire
%   - use of formula vs clause
%   - polymorphic and monomorphic
%   - title of bits of the algorithms
%   - TH1 ugly for height of 1 reasons, can be fixed with case feature
%   - eg or ex -> e.g.
%   - function symbol -> symbol instance (depends on context)
%   - ... -> \dots
%   - comma splices!!!!
%   - add \; at the end of each algorithm line
%   - ``'' -> `'
%   - use \Phi instead of F for formulae
%   - concrete types -> monomorphic types
%   - use in not \in when we are not precisely dealing with set membership
%   - $\Phi$ for problem and $\varphi_1$ etc.
%   - n-uples -> n-tuples
%   - ize -> ise (in cas i forgot any)
%   - remove vertical space before lists (if allowed)
%   - add full stops to end of sentences in itemize
%   - B\"ome -> B\"ohme

\title{Iterative Monomorphisation}

\author[1,2]{Tanguy Bozec}[%
email=tanguy.bozec@ens-paris-saclay.fr,
]
\author[2]{Jasmin Blanchette}[%
email=jasmin.blanchette@ifi.lmu.de,
%url=https://www.tcs.ifi.lmu.de/mitarbeiter/jasmin-blanchette_de.html,
]
\address[1]{ENS Paris-Saclay, Université Paris-Saclay, France}
\address[2]{Institute of Informatics, Ludwig-Maximilians-Universität München, Germany}


\begin{abstract}
Monomorphisation can be used to extend monomorphic provers to support polymorphic logics. We propose an iterative approach, which is necessarily incomplete but which works well in practice. It is implemented in the Zipperposition prover, where it can be used to translate away polymorphism before invoking the monomorphic prover E as a backend. Our evaluation demonstrates that this approach increases Zipperposition's success rate. Moreover, we find iterative monomorphisation to be competitive with native implementations of polymorphism.
\end{abstract}

\begin{keywords}
   Polymorphism\sep
   monomorphism\sep
   automatic theorem proving
\end{keywords}

\maketitle

% target page number: 2-2.5
\section{Introduction}

One of the main applications of automatic theorem provers is to provide automation to users of proof assistants. Many proof assistants, such as HOL4 \cite{slind-norrish-2008}, HOL Light \cite{harrison-2009}, and
Isabelle/HOL \cite{nipkow-et-al-2002}, support rank-1 polymorphism, where type quantification is allowed only at the top level of formulae. On the other hand, many automatic provers operate only on monomorphic logics. One approach to close this gap is to extend provers to natively support polymorphism, as has been done for Vampire \cite{bhayat-reger-2020}. This, however, entails a lot of work that needs to be redone for every prover.

The alternative is to translate polymorphic problems to monomorphic problems. One approach is to encode polymorphism using dedicated function or predicate symbols \cite{mono-trans} in a monomorphic logic. Another approach is to encode polymorphism using {iterative monomorphisation}, as introduced by B\"ohme \cite[Section 2.2.1]{sb-phd}. This method relies on heuristically instantiating the formulae's type variables with concrete types.

By a type version of the compactness theorem, we have that in first order logic, given a polymorphic formula \(\varphi\), there exist an equisatisfiable finite set of monomorphic instances of \(\varphi\). However, such a set cannot be computed \cite[Theorem 1]{expr-poly-types}. As a result, any monomorphisation method based on instantiation of type variables is
bound to be incomplete.

B\"ohme's iterative approach is implemented as part of the SMT (satisfiability modulo theories) integration \cite[Chapter 2]{sb-phd} in Isabelle/HOL. This implementation is also used by Sledgehammer \cite{judgement, hammer} to interface with superposition based automatic theorem provers. However, it is is documented only as a single subsection in his PhD thesis \cite[Section 2.2.1]{sb-phd}.

In this paper, we present an algorithm based on our understanding of his description and implementation (Section~\ref{sec:high level-algorithm}). We also provide a more detailed description to help future implementers. In addition, this description shows some of the ways in which an implementation can be made more efficient and avoid explosions (Section~\ref{sec:low-level-algorithm}).

The algorithm works as follows. We assume problems to be sets of formulae. All symbols of the problem are collected, and the polymorphic instances of symbols are matched against the monomorphic ones. This yields new instances of symbols, both polymorphic and monomorphic. The process is then iterated
a number of times, making use of the newly generated instances.

Consider the unary type constructor \ty{list}. If a formula contains $\ty{list}(\alpha)$, where $\alpha$ is a type variable, it may be possible to generate the types $\ty{list}(\ty{int})$, $\ty{list}(\ty{list}(\ty{int}))$, etc. However, because new types emerge through matching, $\ty{list}(\ty{list}(\ty{int}))$ can be obtained only once the $\ty{list}(\ty{int})$ instance has already been generated. This example also makes it clear that the set of instances that can be generated is infinite.

To keep the number of generated formulae finite, we limit the number of iterations. After the iterations are completed, the new monomorphic symbol instances are used to instantiate the polymorphic symbols in the problem's formulae, generating new monomorphic formulae. Finally, because monomorphic provers generally do not support $n$-ary type constructors, types must be `mangled'; for example, the compound type $\ty{list}(\ty{int})$ could be mangled to the constant $\ty{list\_int}$.

We implemented iterative monomorphisation in Zipperposition \cite{zipp}, a higher order prover written in OCaml. Although Zipperposition is polymorphic, it uses the monomorphic prover E \cite{e} as a backend. This means that E can now be used with polymorphic problems. Moreover, our implementation of the algorithm in Zipperposition can be used as a preprocessor to interface with other stand-alone provers.

Our empirical evaluation on TPTP \cite{tptp} problems attempts to answer three questions (Section~\ref{sec:evaluation}):
\begin{enumerate}
\item Is the new Zipperposition with the E backend more successful on polymorphic problems than Zipperposition without backend?

\item How competitive are monomorphic provers on monomorphised polymorphic problems?

\item Is iterative monomorphisation more effective than the native polymorphism implemented in polymorphic provers?
\end{enumerate}

Our findings are as follows:
\begin{enumerate}
\item Zipperposition benefits substantially from the E backend.

\item E with monomorphisation comes close second to the polymorphic prover Vampire.

\item For Leo-III \cite{leo-iii} and Vampire \cite{vamp}, we find that monomorphisation is indeed more effective than native polymorphism.
\end{enumerate}

% target page number: 0.5-1.5
\section{Preliminaries}
\label{sec:preliminaries}

This algorithm works independently of the structure of the problem's formulae. It relies exclusively on the formulae's monomorphic and polymorphic symbol instances. Type variables are assumed to be implicitly universally quantified at a formula's top level. The precise form of formulae is left unspecified.
Due to this generality, iterative monomorphisation can be used with any reasonable rank-1 polymorphic logic. In particular, it can operate in the polymorphic first and higher order logics embodied by TPTP's TF1 and TH1 syntaxes \cite{blanchette-paskevich-2013,th1}, implemented by several automatic provers.


Our abstract framework relies on the following basic definitions.

\begin{definition}
A (\emph{polymorphic}) \emph{type} \(\tau\) can be a type variable (e.g.\ \(\alpha\)) or
the application of an \(n\)-ary type constructor to \(n\) types (e.g.\ \(\ty{list}(\alpha)\), \(\ty{map}(\ty{int},\ty{string})\)).
If $n = 0$, we omit the parentheses (e.g.\ \(\ty{int}\)).
\end{definition}

\begin{definition}
A type is \emph{monomorphic} if it contains no type variables.
\end{definition}

\begin{definition}
A (function or predicate) {symbol} \(f\) has a \emph{type arity} that defines the number of type arguments it takes. A \emph{symbol instance} is a symbol applied to type arguments listed between angle brackets: \(f\langle \tau_1, \dots, \tau_n\rangle\), where each $\tau_i$ is a type. If $n = 0$, we omit the brackets (e.g.\ $f$).
\end{definition}

\begin{definition}
A (\emph{type}) \emph{substitution} is a partial function mapping a finite number of type variables to corresponding types. Substitutions are written as
$\sigma = \{\alpha_1\mapsto\tau_1, \dots, \alpha_n\mapsto\tau_n\}$. They are assumed to be lifted to formulae; thus, $\sigma(\varphi)$ yields the variant of $\varphi$ in which each $\alpha_i$ is replaced by $\tau_i$.
Given two substitutions \(\tau, \upsilon\), the successive application of \(\tau\) and \(\upsilon\) is denoted by \(\upsilon \circ \tau\).
\end{definition}

\begin{definition}
Two substitutions \(\{\alpha_1 \mapsto \tau_1, \dots, \alpha_m\mapsto\tau_m\}\) and \(\{\beta_1 \mapsto \upsilon_1, \dots, \beta_n\mapsto\upsilon_n\}\) are \emph{compatible} if \(\alpha_i = \beta_j\) implies \(\tau_i = \upsilon_j\) for all \(i, j\).
\end{definition}


\begin{definition}
Given two types \(\tau, \upsilon\), \emph{matching} \(\upsilon\) against \(\tau\) will either fail or yield a substitution \(\sigma\) such that \(\sigma(\upsilon) = \tau\).
\end{definition}

In the following sections, we will always match a polymorphic type $\upsilon$ against a monomorphic type $\tau$.

% target page number: 2-4
\section{High level algorithm}
\label{sec:high level-algorithm}

The iterative monomorphisation algorithm takes a polymorphic problem as input and returns a monomorphic problem. It operates by applying an arbitrary number of iterations. Each iteration takes a polymorphic problem as argument and returns a problem with additional partially instantiated formulae. A single iteration consists of a collection phase and an instantiation phase. Once the iterations are completed, a final step filters out all non-monomorphic formulae returned by the last iteration.

The initial phase of each iteration consists of computing two maps, \(M\) and \(N\), from the input problem~$\Phi$.
%
\begin{enumerate}
\item[\labelitemi] Given a symbol \(f\) occurring in \(\Phi\), the set \(M(f)\) consists of all monomorphic type arguments tuples to which \(f\) is applied in \(\Phi\). For example, if \(\sym{foldl}\langle \ty{nat}, \ty{int}\rangle\) occurs in \(\Phi\), then \((\ty{nat}, \ty{int}) \in M(\sym{foldl}) \).

\item[\labelitemi] Given a formula \(\varphi \in \Phi\) and a symbol \(f\) occurring in \(\varphi\), the set \(N(\varphi)(f)\) consists of all type arguments tuples to which \(f\) is applied in \(\varphi\) and which contains a type variable. For example, if \(\sym{foldl}\langle \ty{nat}, \ty{list}(\alpha)\rangle\) occurs in \(\varphi\), then \((\ty{nat}, \ty{list}(\alpha)) \in N(\varphi)(\sym{foldl}) \).
\end{enumerate}

These definitions depend on the precise form of the input formulae, which has been left undefined. It is important to parametrise \(N\) with \(\varphi\) because type variables are implicitly quantified at the formula level. The formula indicates the scope of type variables. This is not necessary for \(M\) since all the types it contains are monomorphic.

Once the maps \(M\) and \(N\) are initialised, each iteration performs the following steps to create new instances of formulae:

\begin{enumerate}

   \item Create an empty set of formulae \(\Phi'\).

   \item For each formula \(\varphi \in \Phi\) and for each symbol \(f\) occurring in \(\varphi\):
   \begin{enumerate}
    \item[2.1.] For each tuple \((\tau_1, \dots, \tau_n) \in  M(f)\) and each tuple \((\upsilon_1, \dots, \upsilon_n) \in N(\varphi)(f)\),
     for each \(i\), match \(\upsilon_i\) against \(\tau_i\), yielding the substitution \(\sigma_i\) in case of success.

    \item[2.2.] If all \(n\) matchings are successful and the substitutions \(\sigma_i\) are pairwise compatible,
add the formula \((\sigma_1 \circ \dots \circ \sigma_n)(\varphi)\) to \(\Phi'\).
   \end{enumerate}

   \item Return \(\Phi \cup \Phi'\).

\end{enumerate}

The algorithm is clearly sound because the newly generated formulae are instances of the initial problem's formulae, where type variables have been instantiated with monomorphic types. It is, however, not guaranteed to be complete.

\begin{example}Consider the following problem:
\begin{enumerate}
   \item \(\sym{p}\langle \ty{int}\rangle(0)\)
   \item \(\forall a: \alpha{,}\; \mathit{as}:\ty{list}(\alpha){,}\; \sym{p}\langle\alpha\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\alpha)\rangle(\mathit{as})\)
\end{enumerate}
%
The first iteration matches \(\alpha\) against \(\ty{int}\) for $\sym{p}$, generating the formula
%
\begin{enumerate}
   \item[3.] \(\forall a: \ty{int}{,}\; \mathit{as}:\ty{list}(\ty{int}){,}\; \sym{p}\langle\ty{int}\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\ty{int})\rangle(\mathit{as})\)
\end{enumerate}
%
The second iteration matches \(\alpha\) against \(\ty{list}(\ty{int})\), leading to the formula
%
\begin{enumerate}
   \item[4.] \(\forall a: \ty{list}(\ty{int}){,}\; \mathit{as}:\ty{list}(\ty{list}(\ty{int})){,}\; \sym{p}\langle\ty{list}(\ty{int})\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\ty{list}(\ty{int}))\rangle(\mathit{as})\)
\end{enumerate}
%
Similarly the third iteration adds
%
\begin{enumerate}
   \item[5.] \(\forall a: \ty{list}(\ty{list}(\ty{int})){,}\; \mathit{as}:\ty{list}(\ty{list}(\ty{list}(\ty{int}))){,}\; \sym{p}\langle\ty{list}(\ty{list}(\ty{int}))\rangle(a) \rightarrow \sym{p}\langle \ty{list}(\ty{list}(\ty{list}(\ty{int})))\rangle(\mathit{as})\)
\end{enumerate}

\end{example}

This example illustrates how an infinite number of new formulae can be generated from a simple initial problem. Although the example may seem artificial [contrived?], similar problems frequently arise in practice. For example, the \sym{concat} function of Isabelle/HOL, which is characterised in the base case by the equation \(\sym{concat}\langle\alpha\rangle\; \sym{Nil}\langle\ty{list}(\alpha)\rangle = \sym{Nil}\langle\alpha\rangle\), exhibits the same behavior. Any reasonable implementation requires bounds limiting the number of new type arguments, substitutions and formulae to be useful.

% target page number: 2-4
\section{Low level algorithm}
\label{sec:low-level-algorithm}

The algorithm presented in the previous section is simple but too naive for an implementation. In this section, we present a lower level algorithm with the following features.
First, numeric bounds are introduced to stop explosive enumerations.
Second, type arguments tuples are separated into an old set and a new set to avoid re-computing some of the same matchings in successive iterations.
Third, substitutions are directly applied to the type arguments instead of the formulae. This dispenses from having to re-extract the type arguments from the formulae at each iteration. New formulae are generated only once all iterations are complete, in a separate, final step.

The data structures used in the pseudocode are based on the ones used in the high level description. Instead of a map \(M\) from symbols to monomorphic type argument tuples, we now have \(M_\text{old}\) and \(M_\text{new}\), which play the same role whilst also distinguishing between type arguments tuples having already been matched against and those that have not. Similarly, \(N_\text{old}\) and \(N_\text{new}\) replace the map \(N\) from formulae to symbols to non-monomorphic type argument tuples. Finally, we keep track of a set \(S\) of substitutions generated by the matchings. It is used to generate new formulae in the final phase.

All sets referenced in the pseudocode are assumed to be finite. Additionally, this algorithm relies on primitives whose implementation depends on the specifics of the grammar and logic used. They will therefore not be expanded upon. Functions computing the following are assumed to be available: 
\begin{enumerate}
   \item[\labelitemi] \emph{initialisation\((\Phi)\)}, where \(\Phi\) is a set of (polymorphic) formulae, extracts the initial type argument maps \(M\) and \(N\) from \(\Phi\).
   \item[\labelitemi] \emph{type\_variables\((\tau_1, \dots, \tau_n)\)}, where \(\tau_1, \dots,\tau_n\) are types, gathers all the type variables from each type \(\tau_1, \dots, \tau_n\) into a set.
   \item[\labelitemi] \emph{match\((\upsilon, \tau)\)}, where \(\upsilon\) and \(\tau\) are types, will match \(\upsilon\) against \(\tau\) and either fail or return \emph{Success\((\sigma)\)}, where \(\sigma\) is the substitution resulting from the matching. The pseudocode matches only non-monomorphic types against monomorphic types.
   \item[\labelitemi] \emph{domain\((\sigma)\)}, where \(\sigma\) is a substitution, returns the set of type variables \(\alpha\) such that \(\sigma(
   \alpha) \not= \alpha\).
   \item[\labelitemi] \emph{compatible\((\sigma_1, \sigma_2)\)}, where \(\sigma_1\) and \(\sigma_2\) are substitutions, tests the compatibility between \(\sigma_1\) and \(\sigma_2\).
   \item[\labelitemi] Composition and application of substitutions are written using mathematical notations.
   \item[\labelitemi] \emph{mangle\((\Phi)\)}, where \(\Phi\) is a set of monomorphic formulae returns the same set of formulae where all types have been mangled.
\end{enumerate}

\SetKwFunction{IterMono}{iterative\_monomorphisation}
\begin{figure}[b]
\begin{quote}
\begin{algorithm}[H]
\Fn(){\(\IterMono(\Phi)\)}{
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{To}{to}

   \SetKwData{Loop}{num\_loops}\SetKwData{NewFormulae}{\(\Psi\)}
   \SetKwData{Problem}{\(\Phi\)}\SetKwData{AllSubst}{\(S\)}
   \SetKwData{Limit}{total\_new\_formulae}

   \SetKwFunction{Init}{initialisation}\SetKwFunction{FStep}{formula\_mono\_step} 
   \SetKwFunction{TyVars}{type\_variables}\SetKwFunction{MonoSubst}{mono\_substs}
   \SetKwFunction{GenFormulae}{generate\_mono\_formulae}
   \SetKwFunction{Mangle}{mangle}

   \KwData{set \(\Phi\) of polymorphic formulae}
   \KwResult{set of monomorphic formulae}

   \BlankLine

   \((M_{\text{old}}, N_{\text{old}}) \leftarrow (\emptyset, \emptyset)\)\;
   \((M_{\text{new}}, N_{\text{new}}) \leftarrow \Init(\Problem)\)\;

   \AllSubst\(\leftarrow \emptyset\)\;

   \BlankLine

   \For{\(i = 1\) \To \textcolor{ourblueviolet}{\Loop}}{
      \((M_{\text{next}}, N_{\text{next}})\leftarrow(\emptyset,\emptyset)\)\;
      \ForEach{\(\varphi \in \Problem\)} {
         \((M_{\Delta}, N_{\Delta}(\varphi), S_{\Delta})\leftarrow \FStep(M_{\text{old}}, N_{\text{old}}(\varphi), M_{\text{new}}, N_{\text{new}}(\varphi))\)\;
         \(\AllSubst\leftarrow\AllSubst\cup S_{\Delta}\)\;
         \(M_{\text{next}}\leftarrow M_{\text{next}}\cup M_{\Delta}\)\;
         \(N_{\text{next}}(\varphi)\leftarrow N_{\text{next}}(\varphi)\cup N_{\Delta}(\varphi)\)\;
      }

      \((M_{\text{old}}, M_{\text{new}})\leftarrow (M_{\text{old}}\cup M_{\text{new}}, M_{\text{next}})\)\;
      \((N_{\text{old}}, N_{\text{new}})\leftarrow (N_{\text{old}}\cup N_{\text{new}}, N_{\text{next}})\)\;

   }

   \BlankLine

   \Return \(\Mangle(\GenFormulae(\Phi, S))\)
}
\end{algorithm}
\end{quote}
\caption{Pseudocode for iterative monomorphisation}
\label{iter_mono}
\end{figure}


The iterative monomorphisation algorithm is given in Figure~\ref{iter_mono}. It has three phases. The first phase applies a \emph{monomorphisation step} to each formula in \(\Phi\) until the user-set limit, \textcolor{ourblueviolet}{num\_loops}, is reached. This limit is the only bound necessary for the algorithm to terminate. We use the colour blue to identify bounds and code related to bounds. At the end of each of these iterations, the old and new type argument maps are updated with newly generated types. Once these iterations are completed, the first phase is done and the substitutions used to create new type arguments tuples are passed to $\mathit{generate\_mono\_formulae}$ for the second phase. The third phase mangles the composite types of the newly monomorphised formulae. This allows targeting a simply typed logic with no general support for $n$-ary type constructors.
% \cite[Sections 4 and 5]{mono-trans}.
% Paper name is gt

\begin{figure}
\begin{quote}
\begin{algorithm}[H]

   \Fn(){\(\FMonoStep(\varphi, M_{\text{old}}, M_{\text{new}}, N_{\text{old}}(\varphi), N_{\text{new}}(\varphi)\)}{

   \KwData{\begin{minipage}[t]{.8\textwidth}
     \strut polymorphic formula $\varphi$ \\
     old and new monomorphic type argument maps \(M_{\text{old}}, M_{\text{new}}\) \\
     old and new non-monomorphic type argument maps \(N_{\text{old}}(\varphi), N_{\text{new}}(\varphi)\)\strut
      \end{minipage}
   }
   \KwResult{\begin{minipage}[t]{.8\textwidth}
      \strut monomorphic type argument map \\
      non-monomorphic type argument map \\
      set of substitutions\strut
      \end{minipage}
   }
   \BlankLine

   \(\TypeVars \leftarrow \TyVars(\varphi)\)\;

   \textcolor{ourblueviolet}{
   \(\MaxMono \leftarrow \Max(\Min(\MonoFloor, |M_{\text{old}}\cup M_{\text{new}}| \cdot \MonoMult), \MonoCap)\)\;
   \(\MaxPoly \leftarrow \Max(\Min(\PolyFloor, |N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi)| \cdot \PolyMult), \PolyCap)\)\;
   }

   \BlankLine

   \UsedSubst \(\leftarrow\emptyset\)\;

   \BlankLine

   \ForEach{\(\sigma\in \SubstGen(M_{\text{new}}, N_{\text{new}}(\varphi))
   \cup \SubstGen(M_{\text{new}}, N_{\text{old}}(\varphi))
   \cup \SubstGen(M_{\text{old}}, N_{\text{new}}(\varphi))\)}{
   \ForEach{\(f\mapsto (\upsilon_1, \dots,\upsilon_n)\in N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi)\)}{
            \eIf{\(\TyVars(\upsilon_1, \dots, \upsilon_n) \subseteq \Domain(\sigma)\)}{
               \textcolor{ourblueviolet}{
               \uIf{\(|M_{\text{next}}| < \MaxMono\)}{
                  \textcolor{black}{
                  \(M_{\text{next}}(f)\leftarrow M_{\text{next}}(f)\cup\{(\sigma(\upsilon_1),\dots,\sigma(\upsilon_n))\}\)\;
                  \UsedSubst \(\leftarrow \UsedSubst \cup\{\sigma\}\)\;}
               }
               \uElseIf{\(|N_{\text{next}}(\varphi)| \geq \MaxPoly\) }{
                  \(M_{\text{next}} \leftarrow M_{\text{next}}\setminus (M_{\text{old}} \cup M_{\text{new}})\)\;
                  \(N_{\text{next}}(\varphi)\leftarrow N_{\text{next}}(\varphi)\setminus (N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi))\)\;
                  \Return \((M_{\text{next}}, N_{\text{next}}(\varphi), \UsedSubst)\)
               }}
            }{\textcolor{ourblueviolet}{
               \If{\(|N_{\text{next}}(\varphi)| < \MaxPoly\)}{ \textcolor{black} {
               \(N_{\text{next}}(\varphi)(f)\leftarrow N_{\text{next}}(\varphi)(f)\cup\{(\sigma(\upsilon_1),\dots,\sigma(\upsilon_n))\}\)\;
               \(\UsedSubst \leftarrow \UsedSubst \cup\{\sigma\}\)\;
               }}
            }}
      }
   }

   \BlankLine

   \Return \((M_{\text{next}}\setminus (M_{\text{old}} \cup M_{\text{new}}), N_{\text{next}}(\varphi)\setminus (N_{\text{old}}(\varphi)\cup N_{\text{new}}(\varphi)), \UsedSubst)\)
}

\end{algorithm}
\end{quote}
\caption{Pseudocode for formula monomorphisation step}
\label{mono_step}
\end{figure}


The formula monomorphisation algorithm is given in Figure~\ref{mono_step}. It forms the core of the monomorphisation process by computing new type arguments tuples for a single formula. Type argument tuples are matched against each other to obtain a set of substitutions which is iterated over in the outermost loop. 
The separation of type arguments tuples into old and new maps is put to use to ensure that only combinations involving at least one new map are considered. This avoids re-computing some of the matchings processed in previous iterations. Not all such redundant computations can be avoided because the same substitution can be obtained from different matchings. New type argument tuples are obtained by applying each substitution to each non-monomorphic type argument tuple such that at least one type variable in the tuple is instantiated by the substitution.


The total number of type argument tuples can increase cubicly in the number of type arguments tuples at each iteration and can therefore grow doubly exponentially in the number of iterations. We sketch an example of such growth, for a single formula. If we assume that after \(k\) iterations, there are \(N_k\) total type argument tuples divided evenly between monomorphic and non-monomorphic type arguments tuples, then there can be up to \(\bigl(\frac{N_k}{2}\bigr)^2\) successful matches, yielding as many substitutions. Each substitution is then applied to each non-monomorphic type argument for a total of \(\bigl(\frac{N_k}{2}\bigr)^3\) possible new type argument tuples. If half of these new type argument tuples are monomorphic and the other half are non-monomorphic, then the next iteration will begin with \(N_{k+1} = N_k^3 \cdot 2^{-3}\) evenly split type argument tuples. Therefore, the total number of type arguments tuples on the \(k\)th iteration can reach \(N_k = N_0^{3^k} \cdot 2^{\frac{-3^{k+2}+3}{2}}\).

   Depending on the shape and size of the input problem and the number of iterations performed, the doubly exponential growth may be problematic. Introducing bounds addresses this potential issue. The limit on the number of new monomorphic type argument tuples is \(\min(\max(\MonoMult\cdot m, \MonoFloor), \MonoCap)\), where \(m\) is the total number of monomorphic type argument tuples. The components of this limit are
\begin{enumerate}
   \item \MonoCap, an absolute limit on the total number of new type argument tuples;
   \item \MonoMult, which is used to allow the total number of (monomorphic) type argument tuples to grow by a certain proportion of the current number \(m\) of monomorphic type argument tuples;
   \item \MonoFloor, which balances out \MonoMult, preventing \MonoMult from inhibiting new type argument tuple generation if \(m\) is too low.
\end{enumerate}

Similar bounds are used for the non-monomorphic type arguments tuples:
The limit on the number of new non-monomorphic type argument tuples is \(\min(\max(\PolyMult\cdot n, \PolyFloor),\allowbreak \PolyCap)\), where \(n\) is the number of non-monomorphic type argument tuples associated with the current formula. A significant difference with the monomorphic case is that \(n\) depends on the current formula being processed whilst \(m\) does not.
Both in the monomorphic and in the non-monomorphic case, the maximum number of newly generated type argument tuples is fixed per formula and per iteration.

The \emph{matches} function, which computes the substitutions used for generating new type arguments, is given in Figure~\ref{subst_gen}. Each symbol instance from \(N(\varphi)\) is matched against all corresponding symbol instances from \(M\).
For two such symbol instances, types from the non-monomorphic type argument tuple are matched component-wise against the types from the monomorphic type argument tuple. The resulting substitutions are composed if they are compatible. In the pseudocode, this is checked by making sure the \textbf{while} loop has successfully iterated over all elements of the type argument tuple. If any substitutions are incompatible, the matchings are discarded. Since the composition of two compatible substitutions is commutative, the order of composition is irrelevant. The total number of substitutions generated is capped by \textcolor{ourblueviolet}{substitution\_limit}.

\begin{figure}
\begin{quote}
\begin{algorithm}[H]
\SetKwFunction{SubstGen}{matches}
\Fn(){\(\SubstGen(M, N(\varphi))\)}{
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}
   \SetKwData{SubstLimit}{substitution\_limit}
   \SetKwFunction{Success}{Success}\SetKwFunction{Compatible}{compatible}
   \SetKwFunction{Match}{match}
   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
   \SetKw{Break}{break}

   \KwData{\begin{minipage}[t]{.8\textwidth}
      \strut monomorphic type argument map \(M\) \\
      non-monomorphic type argument map \(N(\varphi)\)\strut
      \end{minipage}
   }
   \KwResult{set of substitutions}
   \BlankLine

   \(S\leftarrow \emptyset\)\;

   \BlankLine

   \ForEach{\(f\mapsto (\upsilon_1, \dots,\upsilon_n)\in N(\varphi)\)}{
      \ForEach{\( (\tau_1, \dots,\tau_n) \in M(f) \)}{
         \(\sigma\leftarrow \{\}\)\;
         \(i \leftarrow 1\)\;
         \While{\(i \leq n\)}{
            \eIf{\(\Match(\upsilon_i, \tau_i)\) has the form \(\Success(\sigma_i)\) \And \(\Compatible(\sigma, \sigma_i)\)}{
               \(\strut\sigma\leftarrow\sigma_i\circ\sigma\)
            }
            {\Break}

            \(i\leftarrow i+1\)\;
         }
         
         \If{\(i > n\)}{
            \textcolor{ourblueviolet}{
               \eIf{\(|S| < \SubstLimit\)}{
                  \textcolor{black}{\(S\leftarrow S\cup \{\sigma\}\)\;}
               }
               {\Return \(S\)}
            }
         }
      }

   }

   \BlankLine

   \Return \(S\)\;

}
\end{algorithm}
\end{quote}
\caption{Pseudocode for match generation}
\label{subst_gen}
\end{figure}

\begin{figure}
\begin{quote}
\begin{algorithm}[H]
\Fn(){\(\GenFormulae(\Phi, S)\)}{
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{To}{to}

   \SetKwData{Loop}{num\_loops}\SetKwData{NewFormulae}{\(\Psi\)}
   \SetKwData{Problem}{\(\Phi\)}\SetKwData{AllSubst}{\(S\)}
   \SetKwData{Limit}{total\_new\_formulae}

   \SetKwFunction{Init}{initialisation}\SetKwFunction{FStep}{formula\_mono\_step} 
   \SetKwFunction{TyVars}{type\_variables}\SetKwFunction{MonoSubst}{mono\_substs}
   \SetKwFunction{GenFormulae}{generate\_formulae}

   \KwData{\begin{minipage}[t]{.8\textwidth}
     \strut set \(\Phi\) of polymorphic formulae \\
     set $S$ of substitutions\strut
     \end{minipage}}
   \KwResult{set of monomorphic formulae}

   \BlankLine

   \NewFormulae \(\leftarrow\emptyset\)\;

   \BlankLine

   \ForEach{\(\varphi\in\Phi\) \ST $\varphi$ is non-monomorphic}{
      \ForEach{\(\sigma\in \MonoSubst(\AllSubst, \TyVars{\(\varphi\)}, \emptyset, \{\})\)}{
         \textcolor{ourblueviolet}{
         \eIf{\(|\NewFormulae|<\Limit\)}{
            \textcolor{black}{
            \(\NewFormulae\leftarrow\NewFormulae\cup \{\sigma(\varphi)\}\)\;}
         }
         {\Return \NewFormulae}
      }}
   }

   \BlankLine

   \Return \NewFormulae
}
\end{algorithm}
\end{quote}
\caption{Pseudocode for monomorphic formula generation}
\label{gen_formulae}
\end{figure}


The various bounds presented here overlap to some extent. For instance, having at most \textcolor{ourblueviolet}{substitution\_limit} substitutions generated by \emph{matches} may be sufficient to curb the number of new type argument tuples, making the \textcolor{ourblueviolet}{\MonoCap}, \textcolor{ourblueviolet}{\MonoMult}, \textcolor{ourblueviolet}{\MonoFloor} triplet superfluous. Each bound nonetheless has its uses. For example, problems that lead to few successful matches but many type arguments tuples may benefit from a limit on the number of new type arguments tuples whilst problems for which substitution generation is more explosive may benefit from a limit on the number of generated substitution.

\begin{figure}
\begin{quote}
   \begin{algorithm}[H]

   \SetKwFunction{Compatible}{compatible}
   \SetKwFunction{MonoSubst}{mono\_substs}
   \SetKwFunction{Domain}{domain}
   \SetKwData{Limit}{max\_substs}
   \SetKw{And}{and}\SetKw{True}{true}\SetKw{False}{false}\SetKw{Stop}{stop}
   \SetKw{Let}{let}
   \SetKwInOut{Input}{input}\SetKwInOut{Output}{output}

   \Fn(){\(\MonoSubst(S, V, S_{\text{res}}, \sigma)\)}{

   \KwData{\begin{minipage}[t]{.8\textwidth}
     \strut set \(S\) of substitutions \\
     set \(V\) of type variables \\
     \strut set \(S_{\text{res}}\) of substitutions \\
     substitution \(\sigma\)\strut
      \end{minipage}
   }

   \KwResult{set of substitutions}
   \BlankLine

   \eIf{\(V = \emptyset\)}{
    \Return \(S_{\text{res}}\cup\{\sigma\}\)\;%}
   }
   {
      \Let \(\alpha \) \ST \(\alpha\in V\)\;
      \ForEach{\(\sigma_{\negvthinspace\Delta}\in S\) \ST \(\alpha\in\Domain(\sigma_{\negvthinspace\Delta})\) \And \(\Compatible(\sigma,\sigma_{\negvthinspace\Delta})\)}{
         \textcolor{ourblueviolet}{
         \eIf{\(|S_{\text{res}}|<\Limit\)}{
            \textcolor{black}{
            \(S_{\text{res}}\leftarrow \MonoSubst(S, V\setminus\Domain(\sigma_{\negvthinspace\Delta}), S_{\text{res}}, \sigma_{\negvthinspace\Delta}\circ\sigma)\)\;}
         }
         {\Return \(S_{\text{res}}\)}}
      }
      \Return \(S_{\text{res}}\)\;
   }
   }


\end{algorithm}
\end{quote}
\caption{Pseudocode for monomorphising substitution generation}
\label{mono_substs}
\end{figure}

Once all monomorphisation iterations have been completed, we are left with a set of the substitutions that have been used to generate new type arguments. The last phase uses these substitutions to instantiate the type variables in the input problem's non-monomrophic formuale. In the presence of bounds, the order in which the elements of the set \(S\) of substitutions is traversed affects the formulae resulting from the last phase. As we will discuss in Section~\ref{param_opti}, the best results were obtained when substitutions generated in earlier iterations are ordered first.

The \emph{generate\_mono\_formulae} function is given in Figure~\ref{gen_formulae}.
It generates monomorphising substitutions and applies them to the polymorphic formula of the input problem that they instantiate. Since the substitutions are monomorphising relative to the formula they applied to, the resulting formulae are monomorphic. The \textcolor{ourblueviolet}{total\_new\_formulae} bound is used to control the total number of new formulae. It overlaps with \textcolor{ourblueviolet}{max\_substs} but can be useful to set an absolute limit on the size of the final problem.
%In the Zipperposition implementation, this bound is one of the more important ones as the performance of the E prover can be significantly affected by the number of clauses it is given.

To monomorphise a polymorphic formula, we first compute its {monomorphising substitutions} using the \emph{mono\_substs} function given in Figure~\ref{mono_substs}.
A substitution \(\sigma\) is \emph{monomorphising} for a formula \(\varphi\) if \(\sigma(\varphi)\) is monomorphic. Such substitutions are computed using a recursive function. Given a set \(V\) of type variables and a set \(S\) of substitutions, it will select a substitution \(\sigma_{\negvthinspace\Delta}\) from \(S\) that instantiates at least one of the type variables in \(V\). It is important that \(\sigma_{\negvthinspace\Delta}\) be compatible with \(\sigma\) so that they can be composed and the function recursively called to instantiate the remaining type variables.

The Zipperposition implementation of the \emph{mono\_substs} function uses a map from type variables to substitutions instead of a set to filter the relevant substitutions from \(S\) more efficiently. The \textcolor{ourblueviolet}{max\_substs} bound exists for two main reasons:
\begin{enumerate}
   \item The iterative monomorphisation algorithm can generate up to \textcolor{ourblueviolet}{max\_substs} new monomorphic clause per initial polymorphic clause. Generating an excessive number of new clauses can flood the downstream prover. The final number of output formulae is ensured to be at most \(|\Phi|\cdot \text{\textcolor{ourblueviolet}{max\_substs}}\).
   \item The \emph{mono\_substs} function is the most explosive part of the algorithm. If \(S\) contains \(n\) substitutions that each instantiate exactly one of \(v\) different type variables, up to \(n^v\) monomorphising substititions may be generated. Recall that the total number of type argument tuples that are used to generate \(S\) is doubly exponential in the number of loop iterations.
\end{enumerate}
%[This function can be thought of as exploring the tree of all possible monomorphising substitutions, \(S_{\text{res}}\) would represent the leaves that have already been visited and \(\sigma\) would represent the current node of the tree.]

% target page number: 2-4
\section{Evaluation}
\label{sec:evaluation}

To measure the performance of a Zipperposition instance, we chose as a measure of success the number of problems solved by that instance in under 30 seconds. This setup reflects practical use cases of automatic provers in the context of interactive provers. The problems used for these tests are taken from the TPTP library. The set of selected problems is made up of all problems in the TF1 and TH1 grammars, ie: all first-order and higher-order problems with rank-1 polymorphism. Because Zipperposition does not support reasoning with real numbers, all problems with real numbers or importing axioms with real numbers were removed.

\subsection{Parameter optimisation}
\label{param_opti}

Each bound of the monomorphisation process presents a tradeoff: a higher bound will allow for a more exhaustive instantiations of type variables at the cost of taking more time. Ideally, all possible combinations of values for each bound could be exhaustively tested to find the best compromise between completeness and speed. Given the number of bounds, however, this is not feasible. Instead, closely related bounds are grouped together and combinations of values for bounds in these groups are tested. Once the best performing set of values for a group of bounds is found, these values are assigned to the corresponding bounds as the search for the next group begins. This method requires an initial default set of bounds, the values chosen for these are based on preliminary tests during development.

A potential pitfall of this approach is to overfit the bounds to the problems used as tests. To mitigate this, 500 test problems were taken at random from our set of 1754 selected TPTP problems. Tests whose results are used to inform the value of bounds or parameters always make use of the 500 problems set.

Table [ref] groups bounds that influence the maximum number of newly generated monomorphic type arguments per clause per iteration. It is calculated using three bounds [backwards ref] which therefore form a natural group. Our results show that in this configuration, there seems to be certain range within which the values of the bounds have little effect on performance. Beyond this range, however, the number of problems solved drops-off sharply.
\begin{table}[th]
\caption{Evaluation of bounds for monomorphic type argument generation}
\centering\begin{tabular}{@{}l*{9}{>{\centering\arraybackslash}p{1.5em}}@{}}
   \toprule
   & &&& \multicolumn{3}{c}{floor} \\
   & \multicolumn{3}{c}{50} & \multicolumn{3}{c}{100} & \multicolumn{3}{c}{200}\\
   \cmidrule(l){2-10}
   & &&& \multicolumn{3}{c}{multiplier} \\
   \multirow{1}{2em}{cap} & 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1 & 2\\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(l){8-10}
    250   & 164 & 164 & 164 & 164 & 164 & 163 & 163 & 164 & 164 \\
    500   & 164 & 163 & 164 & 164 & 165 & 163 & 164 & 164 & 164 \\
    750   & 164 & 164 & 165 & 164 & 163 & 164 & 164 & 164 & 164 \\
    %\(\infty\) & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \bottomrule
\end{tabular}
\end{table}

\bigskip
\bigskip

Table [ref 2] fills the same role except it is for bounds limiting the number of new non-monomorphic type arguments. The bound values are lower because non-monomorphic type arguments tend to be more explosive. The results are similar to that of table 1 [ref ].

\begin{table}[th]
\caption{Evaluation of bounds for non-monomorphic type argument generation}
\centering\begin{tabular}{@{}l*{9}{>{\centering\arraybackslash}p{1.1em}}@{}}
   \toprule
   & &&& \multicolumn{3}{c}{floor} \\
   & \multicolumn{3}{c}{0} & \multicolumn{3}{c}{3} & \multicolumn{3}{c}{6}\\
   \cmidrule(l){2-10}
   & &&& \multicolumn{3}{c}{multiplier} \\
    \multirow{1}{2em}{cap} & 0 & 0.5 & 1 & 0 & 0.5 & 1 & 0 & 0.5 & 1 \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(l){8-10}
    10 &   & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    20 &   & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    40 &   & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \(\infty\) & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \bottomrule
\end{tabular}
\end{table}

\begin{table}[th]
\caption{Evaluation of bounds for substitution generation}
\centering\begin{tabular}{@{}l*{4}{>{\centering\arraybackslash}p{1em}}@{}}
   \toprule
   & \multicolumn{4}{c}{mono subst}\\
   \multirow{1}{4em}{subst cap} & 2 & 5 & 7 & 10\\
   \midrule
   50   & 0 & 0 & 0 & 0\\
   100  & 0 & 0 & 0 & 0\\
   500  & 0 & 0 & 0 & 0\\
   \(\infty\) & 0 & 0 & 0 & 0\\
   
   \bottomrule
\end{tabular}
\end{table}

This table groups two bounds that directly affect the number of clauses generated, a first one that allows at most a number of new clauses equal to `multiplier' times the original number of clauses. And the cap that gives an absolute bound over the total number of clauses generated.

The choice to also include e-timeout in this table is due to the fact that E being successful in solving a monomorphised problem in a certain time limit has been observed to be highly dependent on the number of clauses it is given.

\begin{table}[th]
\caption{Evaluation of bounds directly related to the size of the output problem}
\centering\begin{tabular}{@{}l*{9}{>{\centering\arraybackslash}p{1.1em}}@{}}
   \toprule
   & &&& \multicolumn{3}{c}{cap} \\
   & \multicolumn{3}{c}{500} & \multicolumn{3}{c}{2000} & \multicolumn{3}{c}{\(\infty\)}\\
   \cmidrule(l){2-10}
   & &&& \multicolumn{3}{c}{multiplier} \\
    \multirow{1}{5.4em}{E timeout (s)} & 1 & 2 & 3 & 1 & 2 & 3 & 1 & 2 & 3 \\
    \cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(l){8-10}
    2   & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    5   & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    10  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \(\infty\)& 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
    \bottomrule
\end{tabular}
\end{table}
The next table gathers the bounds linked to substitutions generation, the first one limits the number of monomorphising substitutions that are generated per clause during the final phase. The second one gives an absolute cap on the overall number of substitutions generated at each clause during the type argument generation.


This last table attempts to determine which are the best bounds related to the depth at which the monomorphisation problem is run as well as how long zipperposition is allowed to run before monomorphisation (and the subsequent call of E) is ran.

\begin{table}[th]
% not super happy with caption
\caption{Evaluation of parameters indirectly related to the size of the output problem}
\centering\begin{tabular}{@{}l*{4}{>{\centering\arraybackslash}p{1em}}@{}}
   \toprule
   & \multicolumn{4}{c}{loop nb} \\
   \multirow{1}{4.5em}{E call step} & 2 & 3 & 4 & 5\\
   \midrule
   0 & 0 & 0 & 0 & 0\\
   15 & 0 & 0 & 0 & 0\\
   45 & 0 & 0 & 0 & 0\\
   90 & 0 & 0 & 0 & 0\\
   
   \bottomrule
\end{tabular}
\end{table}



\subsection{Monomorphisation as preprocessor}

To evaluate the usefulness of iterative monomorphisation as an alternative to native polymorphism, several competitive higher-order polymorphic provers were run on the set of TPTP test problems. The total number of problems solved the ``Native'' results shown in the table. Evaluation of the monomorphisation approach is done in two steps, first each problem is monomorphised using the [insert configuration] configurations [options?]. Secondly, each prover is ran on the monomorphised problem and the results are tallied in the ``Mono'' column of the table. In addition to the polymorphic provers used in the ``Native'' tests, two monomorphic provers are run on the monomorphised problems. Note that instead of running each prover 30 seconds on the monomorphised problems, the monomorphisation time is subtracted to compare fairly against the ``Native'' column which does not have a similar preprocessing phase.

The ``Union'' column, adds up the total number of problems solved by both tests. It serves as an indicator of the usefulness of monomorphisation as a tool in a portfolio configuration.

\begin{table}[ht]
\caption{Evaluation of native polymorphism vs.\ monomorphisation}
\centering\begin{tabular}{@{}lccc@{}}
   \toprule
   & Native & Mono & Union \\
   \midrule
   E  &   & 0 & 0 \\
   Leo-III & 0 & 0 & 0 \\
   Satallax &  & 0 & 0 \\
   Vampire & 0 & 0 & 0 \\
   Zipperposition & 0 & 0 & 0 \\[1.5\jot]
   Total & 0 & 0 & 0 \\
   \bottomrule
\end{tabular}
\end{table}

\subsection{E as Zipperposition backend}

\begin{table}[ht]
\caption{Evaluation of Zipperposition without E vs. with E}
\centering\begin{tabular}{@{}lccc@{}}
   \toprule
   & without E & with E & Union \\
   \midrule
   Zipperposition & 0 & 0 & 0 \\
   \bottomrule
\end{tabular}
\end{table}

\break

% target page number: 0.5-1
\section{Related work}
\label{sec:related-work}

  * explicitly quantified formulas a la TPTP, existentials, how to eliminate

  * Böhme

% target page number: 0.5-1
\section{Conclusion}
\label{sec:conclusion}

% summary 

% Future avenues

\section*{Acknowledgements}

* Sascha Böhme

\bibliography{citations}

\end{document}
